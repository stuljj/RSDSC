{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from post_clustering import spectral_clustering, acc, nmi\n",
    "import scipy.io as sio\n",
    "import math\n",
    "from torch.autograd import Variable\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn import cluster\n",
    "from scipy.linalg import sqrtm\n",
    "from numpy.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sio.loadmat('datasets/ORL_32x32.mat')\n",
    "x, y = data['fea'].reshape((-1, 1, 32, 32)), data['gnd']\n",
    "y = np.squeeze(y - 1)  \n",
    "\n",
    "# network and optimization parameters\n",
    "num_sample = x.shape[0]\n",
    "num_classes = 40 \n",
    "num_fea = 80 \n",
    "channels = [1, 3, 3, 5]\n",
    "kernels = [3, 3, 3]\n",
    "gamma1, gamma2, gamma3, gamma4 = 0.1 , 0.01 , 8 , 1.2\n",
    "ratio = 0.8      \n",
    "t0 = 5 \n",
    "t_dp = 12\n",
    "k_dp = 10\n",
    "shrink = 1\n",
    "epochs = 940\n",
    "lr = 1e-3\n",
    "update = 1 \n",
    "p = 1 \n",
    "rw_time = 2000\n",
    "\n",
    "# post clustering parameters\n",
    "alpha = 0.2  # threshold of C\n",
    "dim_subspace = 4  # dimension of each subspace\n",
    "ro = 1  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dSamePad(nn.Module):\n",
    "    \"\"\"\n",
    "    Implement Tensorflow's 'SAME' padding mode in Conv2d.\n",
    "    When an odd number, say `m`, of pixels are need to pad, Tensorflow will pad one more column at right or one more\n",
    "    row at bottom. But Pytorch will pad `m+1` pixels, i.e., Pytorch always pads in both sides.\n",
    "    So we can pad the tensor in the way of Tensorflow before call the Conv2d module.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super(Conv2dSamePad, self).__init__()\n",
    "        self.kernel_size = kernel_size if type(kernel_size) in [list, tuple] else [kernel_size, kernel_size]\n",
    "        self.stride = stride if type(stride) in [list, tuple] else [stride, stride]\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_height = x.size(2)\n",
    "        in_width = x.size(3)\n",
    "        out_height = math.ceil(float(in_height) / float(self.stride[0]))\n",
    "        out_width = math.ceil(float(in_width) / float(self.stride[1]))\n",
    "        pad_along_height = ((out_height - 1) * self.stride[0] + self.kernel_size[0] - in_height)\n",
    "        pad_along_width = ((out_width - 1) * self.stride[1] + self.kernel_size[1] - in_width)\n",
    "        pad_top = math.floor(pad_along_height / 2)\n",
    "        pad_left = math.floor(pad_along_width / 2)\n",
    "        pad_bottom = pad_along_height - pad_top\n",
    "        pad_right = pad_along_width - pad_left\n",
    "        return F.pad(x, [pad_left, pad_right, pad_top, pad_bottom], 'constant', 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvTranspose2dSamePad(nn.Module):\n",
    "    \"\"\"\n",
    "    This module implements the \"SAME\" padding mode for ConvTranspose2d as in Tensorflow.\n",
    "    A tensor with width w_in, feed it to ConvTranspose2d(ci, co, kernel, stride), the width of output tensor T_nopad:\n",
    "        w_nopad = (w_in - 1) * stride + kernel\n",
    "    If we use padding, i.e., ConvTranspose2d(ci, co, kernel, stride, padding, output_padding), the width of T_pad:\n",
    "        w_pad = (w_in - 1) * stride + kernel - (2*padding - output_padding) = w_nopad - (2*padding - output_padding)\n",
    "    Yes, in ConvTranspose2d, more padding, the resulting tensor is smaller, i.e., the padding is actually deleting row/col.\n",
    "    If `pad`=(2*padding - output_padding) is odd, Pytorch deletes more columns in the left, i.e., the first ceil(pad/2) and\n",
    "    last `pad - ceil(pad/2)` columns of T_nopad are deleted to get T_pad.\n",
    "    In contrast, Tensorflow deletes more columns in the right, i.e., the first floor(pad/2) and last `pad - floor(pad/2)`\n",
    "    columns are deleted.\n",
    "    For the height, Pytorch deletes more rows at top, while Tensorflow at bottom.\n",
    "    In practice, we usually want `w_pad = w_in * stride`, i.e., the \"SAME\" padding mode in Tensorflow,\n",
    "    so the number of columns to delete:\n",
    "        pad = 2*padding - output_padding = kernel - stride\n",
    "    We can solve the above equation and get:\n",
    "        padding = ceil((kernel - stride)/2), and\n",
    "        output_padding = 2*padding - (kernel - stride) which is either 1 or 0.\n",
    "    But to get the same result with Tensorflow, we should delete values by ourselves instead of using padding and\n",
    "    output_padding in ConvTranspose2d.\n",
    "    To get there, we check the following conditions:\n",
    "    If pad = kernel - stride is even, we can directly set padding=pad/2 and output_padding=0 in ConvTranspose2d.\n",
    "    If pad = kernel - stride is odd, we can use ConvTranspose2d to get T_nopad, and then delete `pad` rows/columns by\n",
    "    ourselves; or we can use ConvTranspose2d to delete `pad - 1` by setting `padding=(pad - 1) / 2` and `ouput_padding=0`\n",
    "    and then delete the last row/column of the resulting tensor by ourselves.\n",
    "    Here we implement the former case.\n",
    "    This module should be called after the ConvTranspose2d module with shared kernel_size and stride values.\n",
    "    And this module can only output a tensor with shape `stride * size_input`.\n",
    "    A more flexible module can be found in `yaleb.py` which can output arbitrary size as specified.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super(ConvTranspose2dSamePad, self).__init__()\n",
    "        self.kernel_size = kernel_size if type(kernel_size) in [list, tuple] else [kernel_size, kernel_size]\n",
    "        self.stride = stride if type(stride) in [list, tuple] else [stride, stride]\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_height = x.size(2)\n",
    "        in_width = x.size(3)\n",
    "        pad_height = self.kernel_size[0] - self.stride[0]\n",
    "        pad_width = self.kernel_size[1] - self.stride[1]\n",
    "        pad_top = pad_height // 2\n",
    "        pad_bottom = pad_height - pad_top\n",
    "        pad_left = pad_width // 2\n",
    "        pad_right = pad_width - pad_left\n",
    "        return x[:, :, pad_top:in_height - pad_bottom, pad_left: in_width - pad_right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAE(nn.Module):\n",
    "    def __init__(self, channels, kernels):\n",
    "        \"\"\"\n",
    "        :param channels: a list containing all channels including the input image channel (1 for gray, 3 for RGB)\n",
    "        :param kernels:  a list containing all kernel sizes, it should satisfy: len(kernels) = len(channels) - 1.\n",
    "        \"\"\"\n",
    "        super(ConvAE, self).__init__()\n",
    "        assert isinstance(channels, list) and isinstance(kernels, list)\n",
    "        self.encoder = nn.Sequential()\n",
    "        for i in range(1, len(channels)):\n",
    "            #  Each layer will divide the size of feature map by 2\n",
    "            self.encoder.add_module('pad%d' % i, Conv2dSamePad(kernels[i - 1], 2))\n",
    "            self.encoder.add_module('conv%d' % i,\n",
    "                                    nn.Conv2d(channels[i - 1], channels[i], kernel_size=kernels[i - 1], stride=2))\n",
    "            self.encoder.add_module('relu%d' % i, nn.ReLU(True))\n",
    "\n",
    "        self.decoder = nn.Sequential()\n",
    "        channels = list(reversed(channels))\n",
    "        kernels = list(reversed(kernels))\n",
    "        for i in range(len(channels) - 1):\n",
    "            # Each layer will double the size of feature map\n",
    "            self.decoder.add_module('deconv%d' % (i + 1),\n",
    "                                    nn.ConvTranspose2d(channels[i], channels[i + 1], kernel_size=kernels[i], stride=2))\n",
    "            self.decoder.add_module('padd%d' % i, ConvTranspose2dSamePad(kernels[i], 2))\n",
    "            self.decoder.add_module('relud%d' % i, nn.ReLU(True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        y = self.decoder(h)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfExpression(nn.Module):\n",
    "    def __init__(self, n):  \n",
    "        super(SelfExpression, self).__init__()\n",
    "        self.Coefficient = nn.Parameter(1.0e-8 * torch.ones(n, n, dtype=torch.float32), requires_grad=True)\n",
    "\n",
    "    def forward(self, x):  \n",
    "        y = torch.matmul(self.Coefficient, x)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 谱聚类模块(module 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thrC(C,ro): \n",
    "    C = C.detach().cpu()\n",
    "    C = C.numpy()\n",
    "    if ro < 1: \n",
    "        N = C.shape[1] \n",
    "        Cp = np.zeros((N,N))\n",
    "        S = np.abs(np.sort(-np.abs(C),axis=0)) \n",
    "        Ind = np.argsort(-np.abs(C),axis=0) \n",
    "        for i in range(N): \n",
    "            cL1 = np.sum(S[:,i]).astype(float) \n",
    "            stop = False\n",
    "            csum = 0\n",
    "            t = 0\n",
    "            while(stop == False): \n",
    "                csum = csum + S[t,i]\n",
    "                if csum > ro*cL1:  \n",
    "                    stop = True \n",
    "                    Cp[Ind[0:t+1,i],i] = C[Ind[0:t+1,i],i] \n",
    "                t = t + 1\n",
    "    else:\n",
    "        Cp = C\n",
    "\n",
    "    return Cp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_proC(C, K, d, alpha):  \n",
    "    C = 0.5*(C + C.T)\n",
    "    r = d*K + 1\n",
    "    U, S, _ = svds(C,r,v0 = np.ones(C.shape[0]))\n",
    "    U = U[:,::-1] \n",
    "    S = np.sqrt(S[::-1])\n",
    "    S = np.diag(S)    \n",
    "    U = U.dot(S)\n",
    "    U = normalize(U, norm='l2', axis = 1)       \n",
    "    Z = U.dot(U.T)\n",
    "    Z = Z * (Z>0) \n",
    "    L = np.abs(Z ** alpha) \n",
    "    L = L/L.max()   \n",
    "    L = 0.5 * (L + L.T)    \n",
    "    spectral = cluster.SpectralClustering(n_clusters=K, eigen_solver='arpack', affinity='precomputed',assign_labels='discretize')\n",
    "    spectral.fit(L)\n",
    "    grp = spectral.fit_predict(L)\n",
    "    \n",
    "    uu,ss,vv = svds(L, k = K) \n",
    "    \n",
    "    return C, grp, uu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_structure_matrix(grp, num_classes):\n",
    "    grp = torch.squeeze(grp) \n",
    "    Q = torch.zeros((grp.numel(), num_classes))\n",
    "    for i in range(grp.numel()):\n",
    "        j = grp[i]\n",
    "        Q[i,j] = 1\n",
    "    \n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_Theta(Q):\n",
    "    Theta = torch.zeros((Q.shape[0], Q.shape[0]))\n",
    "    for i in range(Q.shape[0]):\n",
    "        Qq = Q[i].repeat([Q.shape[0],1]) \n",
    "        Theta[i, :] = 1/2*torch.sum(torch.pow((Q - Qq),2), 1) \n",
    "\n",
    "    return Theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加入自监督全连接层模块(module 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSDSC(nn.Module):\n",
    "    def __init__(self, channels, kernels, num_sample, num_classes, num_fea):\n",
    "        super(RSDSC, self).__init__()\n",
    "        self.n = num_sample\n",
    "        self.ae = ConvAE(channels, kernels)\n",
    "        self.self_expression = SelfExpression(self.n)\n",
    "        self.num_classes = num_classes\n",
    "        self.num_fea = num_fea\n",
    "        self.fc = nn.Sequential(torch.nn.Linear(self.num_fea, int(1/2*self.n)), torch.nn.Linear(int(1/2*self.n), self.num_classes))\n",
    "        self.centers = nn.Parameter(torch.zeros(self.num_classes, self.num_classes)) \n",
    "\n",
    "    def forward(self, x):  \n",
    "        z = self.ae.encoder(x)\n",
    "        shape = z.shape \n",
    "        \n",
    "        num_features = shape[1:4].numel() \n",
    "        flat_z = torch.reshape(z, (-1, num_features)) \n",
    "        fc_out = self.fc(flat_z) \n",
    "        \n",
    "        distmat = torch.pow(fc_out, 2).sum(dim=1, keepdim=True).expand(self.n, self.num_classes) + \\\n",
    "                  torch.pow(self.centers, 2).sum(dim=1, keepdim=True).expand(self.num_classes, self.n).t()\n",
    "        distmat.addmm_(1, -2, fc_out, self.centers.t())     \n",
    "               \n",
    "        z = z.view(self.n, -1)  \n",
    "        z_recon = self.self_expression(z)  \n",
    "        \n",
    "        z_recon_reshape = z_recon.view(shape) \n",
    "        x_recon = self.ae.decoder(z_recon_reshape)  \n",
    "        \n",
    "        return z, z_recon, x_recon, fc_out, distmat\n",
    "    \n",
    "    def loss_list(self, fc_out, distmat, grp, gamma3, gamma4, ratio):\n",
    "        QQ = form_structure_matrix(grp, self.num_classes)\n",
    "        Theta = form_Theta(QQ)\n",
    "        Theta = Theta.cuda()\n",
    "        Cq_loss_list = torch.sum(torch.pow(torch.abs(torch.t(self.self_expression.Coefficient)*Theta),1.0),dim=1)\n",
    "        \n",
    "        cross_entropy_list = torch.zeros(self.n).to(device)\n",
    "        for i in range(self.n):\n",
    "            tag = grp[i].view(-1)\n",
    "            out = fc_out[i,:].view(-1, self.num_classes)\n",
    "            cross_entropy_list[i] += F.cross_entropy(out, tag)\n",
    "        \n",
    "        classes = torch.arange(self.num_classes).long()\n",
    "        classes = classes.cuda()\n",
    "        grp = grp.unsqueeze(1).expand(self.n, self.num_classes)\n",
    "        mask = grp.eq(classes.expand(self.n, self.num_classes)) \n",
    "        dist = distmat * mask.float()\n",
    "        center_loss_list = dist.clamp(min=1e-12, max=1e+12).sum(dim=1) / self.n\n",
    "\n",
    "        sp_loss_list = gamma3*Cq_loss_list + gamma4*(cross_entropy_list + ratio*center_loss_list)\n",
    "        \n",
    "        return sp_loss_list\n",
    "\n",
    "    def loss_fn(self, x, z, z_recon, x_recon, sp_loss_list, gamma1, gamma2, V):\n",
    "        loss_ae = F.mse_loss(x_recon, x, reduction='sum')  \n",
    "        loss_selfExp = F.mse_loss(z_recon, z, reduction='sum')\n",
    "        sp_loss = torch.sum(torch.mul(V, sp_loss_list))\n",
    "        loss_coef = torch.sum(torch.pow(self.self_expression.Coefficient, 2)) \n",
    "        Coef_diag = torch.diag(self.self_expression.Coefficient)\n",
    "        diag_list = torch.pow(Coef_diag, 2.0)\n",
    "        diag_loss = torch.sum(diag_list)\n",
    "        \n",
    "        loss = sp_loss + gamma1 * loss_coef + diag_loss + loss_ae + gamma2*loss_selfExp\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RSDSC(\n",
       "  (ae): ConvAE(\n",
       "    (encoder): Sequential(\n",
       "      (pad1): Conv2dSamePad()\n",
       "      (conv1): Conv2d(1, 3, kernel_size=(3, 3), stride=(2, 2))\n",
       "      (relu1): ReLU(inplace)\n",
       "      (pad2): Conv2dSamePad()\n",
       "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2))\n",
       "      (relu2): ReLU(inplace)\n",
       "      (pad3): Conv2dSamePad()\n",
       "      (conv3): Conv2d(3, 5, kernel_size=(3, 3), stride=(2, 2))\n",
       "      (relu3): ReLU(inplace)\n",
       "    )\n",
       "    (decoder): Sequential(\n",
       "      (deconv1): ConvTranspose2d(5, 3, kernel_size=(3, 3), stride=(2, 2))\n",
       "      (padd0): ConvTranspose2dSamePad()\n",
       "      (relud0): ReLU(inplace)\n",
       "      (deconv2): ConvTranspose2d(3, 3, kernel_size=(3, 3), stride=(2, 2))\n",
       "      (padd1): ConvTranspose2dSamePad()\n",
       "      (relud1): ReLU(inplace)\n",
       "      (deconv3): ConvTranspose2d(3, 1, kernel_size=(3, 3), stride=(2, 2))\n",
       "      (padd2): ConvTranspose2dSamePad()\n",
       "      (relud2): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (self_expression): SelfExpression()\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=80, out_features=200, bias=True)\n",
       "    (1): Linear(in_features=200, out_features=40, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsdsc = RSDSC(channels, kernels, num_sample, num_classes, num_fea)\n",
    "rsdsc.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train(读取预训练模型，跳过stage1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diffusion Processing\n",
    "\n",
    "#Sparse the affinity matrix by k-nearst neighbor\n",
    "def knnSparse(W,k):\n",
    "    n = W.shape[0]\n",
    "    idx_knn = np.argsort(-W, 1) \n",
    "    W_knn = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        W_knn[i, idx_knn[i, 0:k]] = W[i, idx_knn[i, 0:k]]\n",
    "    W_knn = (W_knn + W_knn.T)/2\n",
    "    return W_knn\n",
    "\n",
    "def IterativeDiffusionTPGKNN(W, k, shrink):\n",
    "    W = 1/2*(np.abs(W) + np.abs(W.T))   \n",
    "    #Pre-processing of affinity matrix W\n",
    "    d = np.sum(W,1)\n",
    "    D = np.diag(d + np.spacing(1))\n",
    "    W = W - np.diag(np.diag(W)) + D\n",
    "\n",
    "    #Normalization:W = W ./ repmat(sum(W, 2)+eps, 1, n)\n",
    "    d = np.sum(W,1)\n",
    "    D = np.diag(d + np.spacing(1))\n",
    "    W = np.dot(inv(D), W) #nomalize the row of W\n",
    "    S = shrink*knnSparse(W, k)\n",
    "    WW = S\n",
    "    maxIter = 50 \n",
    "    epsilon = 1e-2\n",
    "     \n",
    "    for t in range(maxIter):\n",
    "        temp = np.dot((np.dot(S,WW)),S.T) + np.eye(max(WW.shape))  \n",
    "        if np.linalg.norm(temp-WW, ord='fro') < epsilon: \n",
    "            break\n",
    "        WW = temp\n",
    "    \n",
    "    WW = knnSparse(WW, k)\n",
    "    \n",
    "    return WW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample weight estimating\n",
    "\n",
    "def R_graph(R, p, rw_time):\n",
    "    #compute transition P from R \n",
    "    R_norm = np.linalg.norm(np.abs(R), ord=p, axis=1, keepdims=True)\n",
    "    P = R/(R_norm + np.spacing(1)) #transition matrix\n",
    "    #compute \\pi from P \n",
    "    N = R.shape[0]\n",
    "    PI = 1/N*np.ones((1,N)) #state probability distribution\n",
    "    if rw_time == 0:\n",
    "        PI_bar = np.ones((1,N))\n",
    "    else:\n",
    "        PI_bar = np.zeros((1,N))\n",
    "        for i in range(rw_time):\n",
    "            PI = np.dot(PI, P)\n",
    "            PI_bar = PI_bar + PI  \n",
    "        PI_bar = PI_bar/rw_time\n",
    "        \n",
    "    return PI_bar\n",
    "\n",
    "def cluster_rg(C, grp, p, rw_time, x, epoch):\n",
    "    if isinstance(C, torch.Tensor):\n",
    "        C = C.detach().cpu().numpy()\n",
    "    if isinstance(grp, torch.Tensor):\n",
    "        grp = grp.detach().cpu().numpy()\n",
    "    grp = np.squeeze(grp)\n",
    "    grp_classes = np.unique(grp)\n",
    "    num_samples = grp.shape[0]\n",
    "    V = np.zeros(num_samples)\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        x = x.detach().cpu().numpy()\n",
    "    x = np.squeeze(x).transpose(0,2,1)\n",
    "    for i in grp_classes.tolist():\n",
    "        location = np.where((i==grp)==True)\n",
    "        if location[0].shape[0] == 1:\n",
    "            v = np.array([[0]])\n",
    "        else:\n",
    "            x_grp = x[location][:][:]\n",
    "            R = np.squeeze(C[location][:,location])\n",
    "            v = R_graph(R, p, rw_time)\n",
    "        for j,k in zip(np.nditer(location), range(location[0].shape[0])):\n",
    "            V[j] += v[:,k]\n",
    "            \n",
    "    V = V.reshape(1,-1)\n",
    "    # normalization\n",
    "    _range = np.max(V,1) - np.min(V,1)\n",
    "    if _range != 0:\n",
    "        V = (V - np.min(V,1)) / _range * 0.5 + 0.5\n",
    "    return V "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, x, y, lr, device, alpha, dim_subspace, ro, show, t0, t_dp, k_dp, gamma1, gamma2, gamma3, gamma4, ratio, update, p, rw_time, shrink):\n",
    "    \n",
    "    optimizer = optim.Adam([{\"params\" : model.fc.parameters()},\n",
    "                            {\"params\" : model.ae.parameters()},\n",
    "                            {\"params\" : model.self_expression.parameters()},\n",
    "                            {\"params\" : model.centers, lr : 0.5}],\n",
    "                           lr=lr)\n",
    "    \n",
    "    if not isinstance(x, torch.Tensor):\n",
    "        x = torch.tensor(x, dtype=torch.float32, device=device)\n",
    "    x = x.to(device)\n",
    "    if isinstance(y, torch.Tensor):\n",
    "        y = y.to('cpu').numpy()\n",
    "\n",
    "    K = len(np.unique(y)) \n",
    "    \n",
    "    C = model.self_expression.Coefficient\n",
    "    C0 = thrC(C, alpha)\n",
    "    _, grp1, _ = post_proC(C0, K, dim_subspace, ro)\n",
    "    \n",
    "    grp1 = torch.tensor(grp1).to(device)\n",
    "\n",
    "    x = Variable(x, requires_grad=False)\n",
    "    \n",
    "    best_performence = 0\n",
    "       \n",
    "    update_counter = 0\n",
    "    \n",
    "    coa, cob = 0.5, 0.5\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        if epoch <= t0: \n",
    "            z, z_recon, x_recon, fc_out, distmat = model(x)\n",
    "            sp_loss_list = model.loss_list(fc_out, distmat, grp1, gamma3, gamma4, ratio)\n",
    "    \n",
    "            if epoch > t0:\n",
    "                C = model.self_expression.Coefficient\n",
    "                C1 = thrC(C, alpha)\n",
    "                V1 = coa*cluster_rg(C1, grp1, p, rw_time, x, epoch) \n",
    "                V2 = cob*R_graph(C1, p, rw_time)\n",
    "                V = V1 + V2\n",
    "                V = torch.from_numpy(V).float().cuda()\n",
    "            else:\n",
    "                V1 = coa*cluster_rg(C0, grp1, p, rw_time, x, epoch) \n",
    "                V2 = cob*R_graph(C0, p, rw_time) \n",
    "                V = V1 + V2\n",
    "                V = torch.from_numpy(V).float().cuda()\n",
    "                \n",
    "                \n",
    "            loss = model.loss_fn(x, z, z_recon, x_recon, sp_loss_list, gamma1, gamma2, V)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print('Epoch %02d:loss=%.4f' %(epoch, loss.item() / grp1.shape[0]))\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            C = model.self_expression.Coefficient\n",
    "            C2 = thrC(C, alpha)\n",
    "            \n",
    "            if epoch <= t_dp: \n",
    "                print('stage2')\n",
    "                _, grp2, _ = post_proC(C2, K, dim_subspace, ro)\n",
    "                  \n",
    "                if (update_counter % update == 0) and (update_counter != 0): \n",
    "                    V1 = coa*cluster_rg(C2, grp2, p, rw_time, x, epoch) \n",
    "                    V2 = cob*R_graph(C2, p, rw_time)\n",
    "                    V = V1 + V2\n",
    "                    V = torch.from_numpy(V).float().cuda()\n",
    "                    update_counter = 1\n",
    "                elif update_counter == 0:\n",
    "                    V1 = coa*cluster_rg(C2, grp2, p, rw_time, x, epoch)\n",
    "                    V2 = cob*R_graph(C2, p, rw_time)\n",
    "                    V0 = V1 + V2\n",
    "                    V0 = torch.from_numpy(V0).float().cuda()\n",
    "                    V = V0\n",
    "                    update_counter += 1\n",
    "                else:\n",
    "                    update_counter += 1\n",
    "                    \n",
    "            else:  \n",
    "                print('stage3')\n",
    "                C3 = IterativeDiffusionTPGKNN(C2, k_dp, shrink)\n",
    "                _, grp2, _ = post_proC(C3, K, dim_subspace, ro)\n",
    "                \n",
    "                if (update_counter % update == 0) and (update_counter != 0):\n",
    "                    V1 = coa*cluster_rg(C3, grp2, p, rw_time, x, epoch) \n",
    "                    V2 = cob*R_graph(C3, p, rw_time)\n",
    "                    V = V1 + V2\n",
    "                    V = torch.from_numpy(V).float().cuda()\n",
    "                    update_counter = 1\n",
    "                elif update_counter == 0:\n",
    "                    V1 = coa*cluster_rg(C3, grp2, p, rw_time, x, epoch)\n",
    "                    V2 = cob*R_graph(C3, p, rw_time)\n",
    "                    V0 = V1 + V2 \n",
    "                    V0 = torch.from_numpy(V0).float().cuda()\n",
    "                    V = V0\n",
    "                    update_counter += 1\n",
    "                else:\n",
    "                    update_counter += 1\n",
    "\n",
    "            print('Epoch %02d: acc=%.4f, nmi=%.4f' %(epoch, acc(y, grp2), nmi(y, grp2)))\n",
    "            if acc(y, grp2) > best_performence:\n",
    "                best_performence = acc(y, grp2)\n",
    "            \n",
    "            grp2 = torch.tensor(grp2).to(device)\n",
    "            z, z_recon, x_recon, fc_out, distmat = model(x)\n",
    "            sp_loss_list = model.loss_list(fc_out, distmat, grp2, gamma3, gamma4, ratio)\n",
    "            loss = model.loss_fn(x, z, z_recon, x_recon, sp_loss_list, gamma1, gamma2, V)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    print('best_performence = %.4f'%best_performence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_freq=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained ae weights are loaded successfully.\n",
      "Epoch 00:loss=15238909.4400\n",
      "Epoch 01:loss=15329844.4800\n",
      "Epoch 02:loss=15370977.2800\n",
      "Epoch 03:loss=15395361.2800\n",
      "Epoch 04:loss=15407050.2400\n",
      "Epoch 05:loss=15409199.3600\n",
      "stage2\n",
      "Epoch 06: acc=0.3125, nmi=0.5449\n",
      "stage2\n",
      "Epoch 07: acc=0.2750, nmi=0.5348\n",
      "stage2\n",
      "Epoch 08: acc=0.3225, nmi=0.5496\n",
      "stage2\n",
      "Epoch 09: acc=0.3275, nmi=0.5622\n",
      "stage2\n",
      "Epoch 10: acc=0.3075, nmi=0.5459\n",
      "stage2\n",
      "Epoch 11: acc=0.3275, nmi=0.5580\n",
      "stage2\n",
      "Epoch 12: acc=0.3050, nmi=0.5420\n",
      "stage3\n",
      "Epoch 13: acc=0.1725, nmi=0.3952\n",
      "stage3\n",
      "Epoch 14: acc=0.1700, nmi=0.3904\n",
      "stage3\n",
      "Epoch 15: acc=0.1900, nmi=0.4031\n",
      "stage3\n",
      "Epoch 16: acc=0.1800, nmi=0.3884\n",
      "stage3\n",
      "Epoch 17: acc=0.1750, nmi=0.3908\n",
      "stage3\n",
      "Epoch 18: acc=0.1775, nmi=0.4014\n",
      "stage3\n",
      "Epoch 19: acc=0.1800, nmi=0.4086\n",
      "stage3\n",
      "Epoch 20: acc=0.1775, nmi=0.4035\n",
      "stage3\n",
      "Epoch 21: acc=0.1750, nmi=0.4018\n",
      "stage3\n",
      "Epoch 22: acc=0.1750, nmi=0.3963\n",
      "stage3\n",
      "Epoch 23: acc=0.1750, nmi=0.3934\n",
      "stage3\n",
      "Epoch 24: acc=0.1900, nmi=0.4063\n",
      "stage3\n",
      "Epoch 25: acc=0.1925, nmi=0.4096\n",
      "stage3\n",
      "Epoch 26: acc=0.1900, nmi=0.4050\n",
      "stage3\n",
      "Epoch 27: acc=0.2025, nmi=0.4189\n",
      "stage3\n",
      "Epoch 28: acc=0.2050, nmi=0.4182\n",
      "stage3\n",
      "Epoch 29: acc=0.2075, nmi=0.4218\n",
      "stage3\n",
      "Epoch 30: acc=0.2275, nmi=0.4550\n",
      "stage3\n",
      "Epoch 31: acc=0.1675, nmi=0.3663\n",
      "stage3\n",
      "Epoch 32: acc=0.1625, nmi=0.3913\n",
      "stage3\n",
      "Epoch 33: acc=0.1625, nmi=0.3882\n",
      "stage3\n",
      "Epoch 34: acc=0.1650, nmi=0.3911\n",
      "stage3\n",
      "Epoch 35: acc=0.1750, nmi=0.4032\n",
      "stage3\n",
      "Epoch 36: acc=0.1700, nmi=0.4060\n",
      "stage3\n",
      "Epoch 37: acc=0.1750, nmi=0.3862\n",
      "stage3\n",
      "Epoch 38: acc=0.1725, nmi=0.3668\n",
      "stage3\n",
      "Epoch 39: acc=0.2250, nmi=0.4757\n",
      "stage3\n",
      "Epoch 40: acc=0.2450, nmi=0.4637\n",
      "stage3\n",
      "Epoch 41: acc=0.2900, nmi=0.5140\n",
      "stage3\n",
      "Epoch 42: acc=0.2675, nmi=0.5017\n",
      "stage3\n",
      "Epoch 43: acc=0.2775, nmi=0.5076\n",
      "stage3\n",
      "Epoch 44: acc=0.3025, nmi=0.5149\n",
      "stage3\n",
      "Epoch 45: acc=0.2775, nmi=0.5243\n",
      "stage3\n",
      "Epoch 46: acc=0.2875, nmi=0.5262\n",
      "stage3\n",
      "Epoch 47: acc=0.2650, nmi=0.4899\n",
      "stage3\n",
      "Epoch 48: acc=0.2650, nmi=0.4878\n",
      "stage3\n",
      "Epoch 49: acc=0.2625, nmi=0.4984\n",
      "stage3\n",
      "Epoch 50: acc=0.2725, nmi=0.5034\n",
      "stage3\n",
      "Epoch 51: acc=0.2750, nmi=0.4922\n",
      "stage3\n",
      "Epoch 52: acc=0.2725, nmi=0.5026\n",
      "stage3\n",
      "Epoch 53: acc=0.2725, nmi=0.4897\n",
      "stage3\n",
      "Epoch 54: acc=0.2900, nmi=0.5007\n",
      "stage3\n",
      "Epoch 55: acc=0.2700, nmi=0.5047\n",
      "stage3\n",
      "Epoch 56: acc=0.2975, nmi=0.5113\n",
      "stage3\n",
      "Epoch 57: acc=0.2900, nmi=0.5131\n",
      "stage3\n",
      "Epoch 58: acc=0.3000, nmi=0.5182\n",
      "stage3\n",
      "Epoch 59: acc=0.3150, nmi=0.5490\n",
      "stage3\n",
      "Epoch 60: acc=0.3550, nmi=0.5550\n",
      "stage3\n",
      "Epoch 61: acc=0.3575, nmi=0.5801\n",
      "stage3\n",
      "Epoch 62: acc=0.3625, nmi=0.5875\n",
      "stage3\n",
      "Epoch 63: acc=0.4125, nmi=0.6124\n",
      "stage3\n",
      "Epoch 64: acc=0.4125, nmi=0.6125\n",
      "stage3\n",
      "Epoch 65: acc=0.4275, nmi=0.6188\n",
      "stage3\n",
      "Epoch 66: acc=0.4300, nmi=0.6246\n",
      "stage3\n",
      "Epoch 67: acc=0.4450, nmi=0.6357\n",
      "stage3\n",
      "Epoch 68: acc=0.4725, nmi=0.6586\n",
      "stage3\n",
      "Epoch 69: acc=0.4650, nmi=0.6555\n",
      "stage3\n",
      "Epoch 70: acc=0.4975, nmi=0.6771\n",
      "stage3\n",
      "Epoch 71: acc=0.4800, nmi=0.6672\n",
      "stage3\n",
      "Epoch 72: acc=0.4625, nmi=0.6714\n",
      "stage3\n",
      "Epoch 73: acc=0.4625, nmi=0.6573\n",
      "stage3\n",
      "Epoch 74: acc=0.4700, nmi=0.6570\n",
      "stage3\n",
      "Epoch 75: acc=0.4925, nmi=0.6735\n",
      "stage3\n",
      "Epoch 76: acc=0.4750, nmi=0.6735\n",
      "stage3\n",
      "Epoch 77: acc=0.4875, nmi=0.6671\n",
      "stage3\n",
      "Epoch 78: acc=0.4675, nmi=0.6712\n",
      "stage3\n",
      "Epoch 79: acc=0.4800, nmi=0.6822\n",
      "stage3\n",
      "Epoch 80: acc=0.4975, nmi=0.6817\n",
      "stage3\n",
      "Epoch 81: acc=0.4975, nmi=0.6947\n",
      "stage3\n",
      "Epoch 82: acc=0.5125, nmi=0.6912\n",
      "stage3\n",
      "Epoch 83: acc=0.5200, nmi=0.6938\n",
      "stage3\n",
      "Epoch 84: acc=0.4900, nmi=0.6930\n",
      "stage3\n",
      "Epoch 85: acc=0.5000, nmi=0.7018\n",
      "stage3\n",
      "Epoch 86: acc=0.5575, nmi=0.7240\n",
      "stage3\n",
      "Epoch 87: acc=0.5150, nmi=0.7030\n",
      "stage3\n",
      "Epoch 88: acc=0.5225, nmi=0.7127\n",
      "stage3\n",
      "Epoch 89: acc=0.5275, nmi=0.7193\n",
      "stage3\n",
      "Epoch 90: acc=0.5475, nmi=0.7270\n",
      "stage3\n",
      "Epoch 91: acc=0.5550, nmi=0.7257\n",
      "stage3\n",
      "Epoch 92: acc=0.5675, nmi=0.7323\n",
      "stage3\n",
      "Epoch 93: acc=0.5625, nmi=0.7265\n",
      "stage3\n",
      "Epoch 94: acc=0.5625, nmi=0.7316\n",
      "stage3\n",
      "Epoch 95: acc=0.5800, nmi=0.7500\n",
      "stage3\n",
      "Epoch 96: acc=0.5850, nmi=0.7497\n",
      "stage3\n",
      "Epoch 97: acc=0.5625, nmi=0.7307\n",
      "stage3\n",
      "Epoch 98: acc=0.5725, nmi=0.7433\n",
      "stage3\n",
      "Epoch 99: acc=0.5600, nmi=0.7438\n",
      "stage3\n",
      "Epoch 100: acc=0.5975, nmi=0.7522\n",
      "stage3\n",
      "Epoch 101: acc=0.5825, nmi=0.7508\n",
      "stage3\n",
      "Epoch 102: acc=0.5850, nmi=0.7486\n",
      "stage3\n",
      "Epoch 103: acc=0.5875, nmi=0.7476\n",
      "stage3\n",
      "Epoch 104: acc=0.5975, nmi=0.7524\n",
      "stage3\n",
      "Epoch 105: acc=0.5575, nmi=0.7333\n",
      "stage3\n",
      "Epoch 106: acc=0.5925, nmi=0.7461\n",
      "stage3\n",
      "Epoch 107: acc=0.5750, nmi=0.7456\n",
      "stage3\n",
      "Epoch 108: acc=0.5800, nmi=0.7412\n",
      "stage3\n",
      "Epoch 109: acc=0.5825, nmi=0.7481\n",
      "stage3\n",
      "Epoch 110: acc=0.5625, nmi=0.7377\n",
      "stage3\n",
      "Epoch 111: acc=0.5900, nmi=0.7500\n",
      "stage3\n",
      "Epoch 112: acc=0.5850, nmi=0.7418\n",
      "stage3\n",
      "Epoch 113: acc=0.5850, nmi=0.7522\n",
      "stage3\n",
      "Epoch 114: acc=0.6075, nmi=0.7584\n",
      "stage3\n",
      "Epoch 115: acc=0.5775, nmi=0.7597\n",
      "stage3\n",
      "Epoch 116: acc=0.6200, nmi=0.7614\n",
      "stage3\n",
      "Epoch 117: acc=0.6100, nmi=0.7689\n",
      "stage3\n",
      "Epoch 118: acc=0.6100, nmi=0.7668\n",
      "stage3\n",
      "Epoch 119: acc=0.5950, nmi=0.7558\n",
      "stage3\n",
      "Epoch 120: acc=0.6100, nmi=0.7660\n",
      "stage3\n",
      "Epoch 121: acc=0.6050, nmi=0.7644\n",
      "stage3\n",
      "Epoch 122: acc=0.5975, nmi=0.7616\n",
      "stage3\n",
      "Epoch 123: acc=0.6000, nmi=0.7665\n",
      "stage3\n",
      "Epoch 124: acc=0.6200, nmi=0.7759\n",
      "stage3\n",
      "Epoch 125: acc=0.5950, nmi=0.7608\n",
      "stage3\n",
      "Epoch 126: acc=0.6000, nmi=0.7626\n",
      "stage3\n",
      "Epoch 127: acc=0.6175, nmi=0.7689\n",
      "stage3\n",
      "Epoch 128: acc=0.6075, nmi=0.7691\n",
      "stage3\n",
      "Epoch 129: acc=0.6000, nmi=0.7564\n",
      "stage3\n",
      "Epoch 130: acc=0.5925, nmi=0.7669\n",
      "stage3\n",
      "Epoch 131: acc=0.6000, nmi=0.7597\n",
      "stage3\n",
      "Epoch 132: acc=0.6050, nmi=0.7660\n",
      "stage3\n",
      "Epoch 133: acc=0.6050, nmi=0.7722\n",
      "stage3\n",
      "Epoch 134: acc=0.6050, nmi=0.7736\n",
      "stage3\n",
      "Epoch 135: acc=0.6075, nmi=0.7730\n",
      "stage3\n",
      "Epoch 136: acc=0.6000, nmi=0.7684\n",
      "stage3\n",
      "Epoch 137: acc=0.6275, nmi=0.7809\n",
      "stage3\n",
      "Epoch 138: acc=0.6300, nmi=0.7829\n",
      "stage3\n",
      "Epoch 139: acc=0.6100, nmi=0.7728\n",
      "stage3\n",
      "Epoch 140: acc=0.6150, nmi=0.7802\n",
      "stage3\n",
      "Epoch 141: acc=0.6225, nmi=0.7877\n",
      "stage3\n",
      "Epoch 142: acc=0.6450, nmi=0.7838\n",
      "stage3\n",
      "Epoch 143: acc=0.6400, nmi=0.7894\n",
      "stage3\n",
      "Epoch 144: acc=0.6500, nmi=0.7982\n",
      "stage3\n",
      "Epoch 145: acc=0.6175, nmi=0.7787\n",
      "stage3\n",
      "Epoch 146: acc=0.6325, nmi=0.7890\n",
      "stage3\n",
      "Epoch 147: acc=0.5950, nmi=0.7755\n",
      "stage3\n",
      "Epoch 148: acc=0.5800, nmi=0.7673\n",
      "stage3\n",
      "Epoch 149: acc=0.5975, nmi=0.7720\n",
      "stage3\n",
      "Epoch 150: acc=0.6075, nmi=0.7846\n",
      "stage3\n",
      "Epoch 151: acc=0.5975, nmi=0.7735\n",
      "stage3\n",
      "Epoch 152: acc=0.6150, nmi=0.7802\n",
      "stage3\n",
      "Epoch 153: acc=0.6025, nmi=0.7739\n",
      "stage3\n",
      "Epoch 154: acc=0.5725, nmi=0.7708\n",
      "stage3\n",
      "Epoch 155: acc=0.5975, nmi=0.7755\n",
      "stage3\n",
      "Epoch 156: acc=0.6175, nmi=0.7883\n",
      "stage3\n",
      "Epoch 157: acc=0.5950, nmi=0.7727\n",
      "stage3\n",
      "Epoch 158: acc=0.6150, nmi=0.7865\n",
      "stage3\n",
      "Epoch 159: acc=0.6050, nmi=0.7873\n",
      "stage3\n",
      "Epoch 160: acc=0.6050, nmi=0.7793\n",
      "stage3\n",
      "Epoch 161: acc=0.6025, nmi=0.7807\n",
      "stage3\n",
      "Epoch 162: acc=0.6225, nmi=0.7923\n",
      "stage3\n",
      "Epoch 163: acc=0.6225, nmi=0.7885\n",
      "stage3\n",
      "Epoch 164: acc=0.6250, nmi=0.7947\n",
      "stage3\n",
      "Epoch 165: acc=0.6350, nmi=0.8022\n",
      "stage3\n",
      "Epoch 166: acc=0.6300, nmi=0.7927\n",
      "stage3\n",
      "Epoch 167: acc=0.6250, nmi=0.7965\n",
      "stage3\n",
      "Epoch 168: acc=0.6275, nmi=0.7951\n",
      "stage3\n",
      "Epoch 169: acc=0.6350, nmi=0.7889\n",
      "stage3\n",
      "Epoch 170: acc=0.6500, nmi=0.8007\n",
      "stage3\n",
      "Epoch 171: acc=0.6175, nmi=0.7836\n",
      "stage3\n",
      "Epoch 172: acc=0.6100, nmi=0.7844\n",
      "stage3\n",
      "Epoch 173: acc=0.6050, nmi=0.7806\n",
      "stage3\n",
      "Epoch 174: acc=0.6125, nmi=0.7831\n",
      "stage3\n",
      "Epoch 175: acc=0.6425, nmi=0.7987\n",
      "stage3\n",
      "Epoch 176: acc=0.6325, nmi=0.7985\n",
      "stage3\n",
      "Epoch 177: acc=0.6275, nmi=0.7983\n",
      "stage3\n",
      "Epoch 178: acc=0.6300, nmi=0.8000\n",
      "stage3\n",
      "Epoch 179: acc=0.6425, nmi=0.7959\n",
      "stage3\n",
      "Epoch 180: acc=0.6200, nmi=0.7975\n",
      "stage3\n",
      "Epoch 181: acc=0.6125, nmi=0.7928\n",
      "stage3\n",
      "Epoch 182: acc=0.6075, nmi=0.7882\n",
      "stage3\n",
      "Epoch 183: acc=0.6525, nmi=0.8097\n",
      "stage3\n",
      "Epoch 184: acc=0.6425, nmi=0.8060\n",
      "stage3\n",
      "Epoch 185: acc=0.6375, nmi=0.8059\n",
      "stage3\n",
      "Epoch 186: acc=0.6375, nmi=0.8026\n",
      "stage3\n",
      "Epoch 187: acc=0.6375, nmi=0.8036\n",
      "stage3\n",
      "Epoch 188: acc=0.6450, nmi=0.8022\n",
      "stage3\n",
      "Epoch 189: acc=0.6350, nmi=0.7941\n",
      "stage3\n",
      "Epoch 190: acc=0.6525, nmi=0.8046\n",
      "stage3\n",
      "Epoch 191: acc=0.6325, nmi=0.7973\n",
      "stage3\n",
      "Epoch 192: acc=0.6225, nmi=0.7939\n",
      "stage3\n",
      "Epoch 193: acc=0.6225, nmi=0.8034\n",
      "stage3\n",
      "Epoch 194: acc=0.6125, nmi=0.7927\n",
      "stage3\n",
      "Epoch 195: acc=0.6275, nmi=0.8050\n",
      "stage3\n",
      "Epoch 196: acc=0.6400, nmi=0.8034\n",
      "stage3\n",
      "Epoch 197: acc=0.6500, nmi=0.8136\n",
      "stage3\n",
      "Epoch 198: acc=0.6450, nmi=0.8051\n",
      "stage3\n",
      "Epoch 199: acc=0.6175, nmi=0.8016\n",
      "stage3\n",
      "Epoch 200: acc=0.6225, nmi=0.8092\n",
      "stage3\n",
      "Epoch 201: acc=0.6450, nmi=0.8078\n",
      "stage3\n",
      "Epoch 202: acc=0.6275, nmi=0.7922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage3\n",
      "Epoch 203: acc=0.6350, nmi=0.7934\n",
      "stage3\n",
      "Epoch 204: acc=0.6300, nmi=0.7981\n",
      "stage3\n",
      "Epoch 205: acc=0.6375, nmi=0.7999\n",
      "stage3\n",
      "Epoch 206: acc=0.6400, nmi=0.8004\n",
      "stage3\n",
      "Epoch 207: acc=0.6525, nmi=0.8109\n",
      "stage3\n",
      "Epoch 208: acc=0.6350, nmi=0.8075\n",
      "stage3\n",
      "Epoch 209: acc=0.6475, nmi=0.8173\n",
      "stage3\n",
      "Epoch 210: acc=0.6525, nmi=0.8131\n",
      "stage3\n",
      "Epoch 211: acc=0.6525, nmi=0.8060\n",
      "stage3\n",
      "Epoch 212: acc=0.6475, nmi=0.8104\n",
      "stage3\n",
      "Epoch 213: acc=0.6400, nmi=0.7988\n",
      "stage3\n",
      "Epoch 214: acc=0.6325, nmi=0.7992\n",
      "stage3\n",
      "Epoch 215: acc=0.6500, nmi=0.7997\n",
      "stage3\n",
      "Epoch 216: acc=0.6600, nmi=0.8156\n",
      "stage3\n",
      "Epoch 217: acc=0.6600, nmi=0.8170\n",
      "stage3\n",
      "Epoch 218: acc=0.6475, nmi=0.8142\n",
      "stage3\n",
      "Epoch 219: acc=0.6500, nmi=0.8114\n",
      "stage3\n",
      "Epoch 220: acc=0.6300, nmi=0.7944\n",
      "stage3\n",
      "Epoch 221: acc=0.6250, nmi=0.7964\n",
      "stage3\n",
      "Epoch 222: acc=0.6525, nmi=0.8152\n",
      "stage3\n",
      "Epoch 223: acc=0.6375, nmi=0.8095\n",
      "stage3\n",
      "Epoch 224: acc=0.6500, nmi=0.8098\n",
      "stage3\n",
      "Epoch 225: acc=0.6375, nmi=0.8076\n",
      "stage3\n",
      "Epoch 226: acc=0.6475, nmi=0.8157\n",
      "stage3\n",
      "Epoch 227: acc=0.6400, nmi=0.8200\n",
      "stage3\n",
      "Epoch 228: acc=0.6525, nmi=0.8186\n",
      "stage3\n",
      "Epoch 229: acc=0.6475, nmi=0.8184\n",
      "stage3\n",
      "Epoch 230: acc=0.6650, nmi=0.8224\n",
      "stage3\n",
      "Epoch 231: acc=0.6600, nmi=0.8189\n",
      "stage3\n",
      "Epoch 232: acc=0.6550, nmi=0.8239\n",
      "stage3\n",
      "Epoch 233: acc=0.6575, nmi=0.8260\n",
      "stage3\n",
      "Epoch 234: acc=0.6875, nmi=0.8251\n",
      "stage3\n",
      "Epoch 235: acc=0.6850, nmi=0.8306\n",
      "stage3\n",
      "Epoch 236: acc=0.6775, nmi=0.8307\n",
      "stage3\n",
      "Epoch 237: acc=0.6700, nmi=0.8228\n",
      "stage3\n",
      "Epoch 238: acc=0.6900, nmi=0.8360\n",
      "stage3\n",
      "Epoch 239: acc=0.6875, nmi=0.8367\n",
      "stage3\n",
      "Epoch 240: acc=0.6825, nmi=0.8293\n",
      "stage3\n",
      "Epoch 241: acc=0.6925, nmi=0.8234\n",
      "stage3\n",
      "Epoch 242: acc=0.6900, nmi=0.8315\n",
      "stage3\n",
      "Epoch 243: acc=0.6950, nmi=0.8309\n",
      "stage3\n",
      "Epoch 244: acc=0.6750, nmi=0.8236\n",
      "stage3\n",
      "Epoch 245: acc=0.6925, nmi=0.8371\n",
      "stage3\n",
      "Epoch 246: acc=0.6900, nmi=0.8328\n",
      "stage3\n",
      "Epoch 247: acc=0.6850, nmi=0.8321\n",
      "stage3\n",
      "Epoch 248: acc=0.6750, nmi=0.8259\n",
      "stage3\n",
      "Epoch 249: acc=0.6775, nmi=0.8199\n",
      "stage3\n",
      "Epoch 250: acc=0.6925, nmi=0.8257\n",
      "stage3\n",
      "Epoch 251: acc=0.6800, nmi=0.8333\n",
      "stage3\n",
      "Epoch 252: acc=0.6850, nmi=0.8227\n",
      "stage3\n",
      "Epoch 253: acc=0.6950, nmi=0.8284\n",
      "stage3\n",
      "Epoch 254: acc=0.6850, nmi=0.8244\n",
      "stage3\n",
      "Epoch 255: acc=0.6875, nmi=0.8264\n",
      "stage3\n",
      "Epoch 256: acc=0.6900, nmi=0.8247\n",
      "stage3\n",
      "Epoch 257: acc=0.6800, nmi=0.8219\n",
      "stage3\n",
      "Epoch 258: acc=0.7125, nmi=0.8351\n",
      "stage3\n",
      "Epoch 259: acc=0.6875, nmi=0.8303\n",
      "stage3\n",
      "Epoch 260: acc=0.6875, nmi=0.8228\n",
      "stage3\n",
      "Epoch 261: acc=0.7150, nmi=0.8271\n",
      "stage3\n",
      "Epoch 262: acc=0.7250, nmi=0.8370\n",
      "stage3\n",
      "Epoch 263: acc=0.7250, nmi=0.8425\n",
      "stage3\n",
      "Epoch 264: acc=0.7225, nmi=0.8340\n",
      "stage3\n",
      "Epoch 265: acc=0.6850, nmi=0.8235\n",
      "stage3\n",
      "Epoch 266: acc=0.7050, nmi=0.8348\n",
      "stage3\n",
      "Epoch 267: acc=0.7000, nmi=0.8304\n",
      "stage3\n",
      "Epoch 268: acc=0.6875, nmi=0.8227\n",
      "stage3\n",
      "Epoch 269: acc=0.6950, nmi=0.8306\n",
      "stage3\n",
      "Epoch 270: acc=0.6925, nmi=0.8268\n",
      "stage3\n",
      "Epoch 271: acc=0.7050, nmi=0.8404\n",
      "stage3\n",
      "Epoch 272: acc=0.6825, nmi=0.8373\n",
      "stage3\n",
      "Epoch 273: acc=0.6925, nmi=0.8426\n",
      "stage3\n",
      "Epoch 274: acc=0.6925, nmi=0.8395\n",
      "stage3\n",
      "Epoch 275: acc=0.6875, nmi=0.8385\n",
      "stage3\n",
      "Epoch 276: acc=0.7100, nmi=0.8433\n",
      "stage3\n",
      "Epoch 277: acc=0.7275, nmi=0.8503\n",
      "stage3\n",
      "Epoch 278: acc=0.7100, nmi=0.8357\n",
      "stage3\n",
      "Epoch 279: acc=0.7100, nmi=0.8432\n",
      "stage3\n",
      "Epoch 280: acc=0.7100, nmi=0.8371\n",
      "stage3\n",
      "Epoch 281: acc=0.7150, nmi=0.8456\n",
      "stage3\n",
      "Epoch 282: acc=0.7300, nmi=0.8513\n",
      "stage3\n",
      "Epoch 283: acc=0.7250, nmi=0.8469\n",
      "stage3\n",
      "Epoch 284: acc=0.7100, nmi=0.8419\n",
      "stage3\n",
      "Epoch 285: acc=0.7250, nmi=0.8489\n",
      "stage3\n",
      "Epoch 286: acc=0.7050, nmi=0.8407\n",
      "stage3\n",
      "Epoch 287: acc=0.7475, nmi=0.8594\n",
      "stage3\n",
      "Epoch 288: acc=0.7475, nmi=0.8665\n",
      "stage3\n",
      "Epoch 289: acc=0.7450, nmi=0.8594\n",
      "stage3\n",
      "Epoch 290: acc=0.7475, nmi=0.8660\n",
      "stage3\n",
      "Epoch 291: acc=0.7100, nmi=0.8418\n",
      "stage3\n",
      "Epoch 292: acc=0.7225, nmi=0.8468\n",
      "stage3\n",
      "Epoch 293: acc=0.7325, nmi=0.8485\n",
      "stage3\n",
      "Epoch 294: acc=0.7325, nmi=0.8546\n",
      "stage3\n",
      "Epoch 295: acc=0.7275, nmi=0.8484\n",
      "stage3\n",
      "Epoch 296: acc=0.6900, nmi=0.8468\n",
      "stage3\n",
      "Epoch 297: acc=0.7325, nmi=0.8564\n",
      "stage3\n",
      "Epoch 298: acc=0.7225, nmi=0.8563\n",
      "stage3\n",
      "Epoch 299: acc=0.7325, nmi=0.8598\n",
      "stage3\n",
      "Epoch 300: acc=0.7450, nmi=0.8640\n",
      "stage3\n",
      "Epoch 301: acc=0.7500, nmi=0.8659\n",
      "stage3\n",
      "Epoch 302: acc=0.7700, nmi=0.8677\n",
      "stage3\n",
      "Epoch 303: acc=0.7550, nmi=0.8650\n",
      "stage3\n",
      "Epoch 304: acc=0.7450, nmi=0.8644\n",
      "stage3\n",
      "Epoch 305: acc=0.7350, nmi=0.8650\n",
      "stage3\n",
      "Epoch 306: acc=0.7575, nmi=0.8754\n",
      "stage3\n",
      "Epoch 307: acc=0.7650, nmi=0.8730\n",
      "stage3\n",
      "Epoch 308: acc=0.7575, nmi=0.8761\n",
      "stage3\n",
      "Epoch 309: acc=0.7650, nmi=0.8667\n",
      "stage3\n",
      "Epoch 310: acc=0.7525, nmi=0.8725\n",
      "stage3\n",
      "Epoch 311: acc=0.7525, nmi=0.8738\n",
      "stage3\n",
      "Epoch 312: acc=0.7600, nmi=0.8722\n",
      "stage3\n",
      "Epoch 313: acc=0.7750, nmi=0.8693\n",
      "stage3\n",
      "Epoch 314: acc=0.7725, nmi=0.8787\n",
      "stage3\n",
      "Epoch 315: acc=0.7650, nmi=0.8695\n",
      "stage3\n",
      "Epoch 316: acc=0.7475, nmi=0.8711\n",
      "stage3\n",
      "Epoch 317: acc=0.7800, nmi=0.8793\n",
      "stage3\n",
      "Epoch 318: acc=0.7750, nmi=0.8758\n",
      "stage3\n",
      "Epoch 319: acc=0.7875, nmi=0.8799\n",
      "stage3\n",
      "Epoch 320: acc=0.7875, nmi=0.8841\n",
      "stage3\n",
      "Epoch 321: acc=0.7775, nmi=0.8754\n",
      "stage3\n",
      "Epoch 322: acc=0.7875, nmi=0.8782\n",
      "stage3\n",
      "Epoch 323: acc=0.7900, nmi=0.8793\n",
      "stage3\n",
      "Epoch 324: acc=0.7875, nmi=0.8791\n",
      "stage3\n",
      "Epoch 325: acc=0.8125, nmi=0.8949\n",
      "stage3\n",
      "Epoch 326: acc=0.7900, nmi=0.8840\n",
      "stage3\n",
      "Epoch 327: acc=0.7950, nmi=0.8919\n",
      "stage3\n",
      "Epoch 328: acc=0.7925, nmi=0.8888\n",
      "stage3\n",
      "Epoch 329: acc=0.7900, nmi=0.8860\n",
      "stage3\n",
      "Epoch 330: acc=0.7975, nmi=0.8883\n",
      "stage3\n",
      "Epoch 331: acc=0.7675, nmi=0.8804\n",
      "stage3\n",
      "Epoch 332: acc=0.8000, nmi=0.8896\n",
      "stage3\n",
      "Epoch 333: acc=0.7900, nmi=0.8884\n",
      "stage3\n",
      "Epoch 334: acc=0.7900, nmi=0.8854\n",
      "stage3\n",
      "Epoch 335: acc=0.7900, nmi=0.8862\n",
      "stage3\n",
      "Epoch 336: acc=0.7900, nmi=0.8874\n",
      "stage3\n",
      "Epoch 337: acc=0.7900, nmi=0.8881\n",
      "stage3\n",
      "Epoch 338: acc=0.7875, nmi=0.8843\n",
      "stage3\n",
      "Epoch 339: acc=0.8150, nmi=0.8950\n",
      "stage3\n",
      "Epoch 340: acc=0.7900, nmi=0.8886\n",
      "stage3\n",
      "Epoch 341: acc=0.8075, nmi=0.8924\n",
      "stage3\n",
      "Epoch 342: acc=0.7875, nmi=0.8880\n",
      "stage3\n",
      "Epoch 343: acc=0.7875, nmi=0.8885\n",
      "stage3\n",
      "Epoch 344: acc=0.7750, nmi=0.8807\n",
      "stage3\n",
      "Epoch 345: acc=0.7900, nmi=0.8828\n",
      "stage3\n",
      "Epoch 346: acc=0.8050, nmi=0.8832\n",
      "stage3\n",
      "Epoch 347: acc=0.8125, nmi=0.8855\n",
      "stage3\n",
      "Epoch 348: acc=0.8125, nmi=0.8915\n",
      "stage3\n",
      "Epoch 349: acc=0.8325, nmi=0.8942\n",
      "stage3\n",
      "Epoch 350: acc=0.8300, nmi=0.8938\n",
      "stage3\n",
      "Epoch 351: acc=0.8225, nmi=0.8994\n",
      "stage3\n",
      "Epoch 352: acc=0.8050, nmi=0.8918\n",
      "stage3\n",
      "Epoch 353: acc=0.8025, nmi=0.8912\n",
      "stage3\n",
      "Epoch 354: acc=0.7850, nmi=0.8851\n",
      "stage3\n",
      "Epoch 355: acc=0.8025, nmi=0.8900\n",
      "stage3\n",
      "Epoch 356: acc=0.7875, nmi=0.8855\n",
      "stage3\n",
      "Epoch 357: acc=0.8025, nmi=0.8937\n",
      "stage3\n",
      "Epoch 358: acc=0.7675, nmi=0.8824\n",
      "stage3\n",
      "Epoch 359: acc=0.7625, nmi=0.8826\n",
      "stage3\n",
      "Epoch 360: acc=0.7800, nmi=0.8886\n",
      "stage3\n",
      "Epoch 361: acc=0.7750, nmi=0.8888\n",
      "stage3\n",
      "Epoch 362: acc=0.8000, nmi=0.8932\n",
      "stage3\n",
      "Epoch 363: acc=0.8025, nmi=0.8978\n",
      "stage3\n",
      "Epoch 364: acc=0.7950, nmi=0.8812\n",
      "stage3\n",
      "Epoch 365: acc=0.7825, nmi=0.8780\n",
      "stage3\n",
      "Epoch 366: acc=0.8025, nmi=0.8904\n",
      "stage3\n",
      "Epoch 367: acc=0.8050, nmi=0.8949\n",
      "stage3\n",
      "Epoch 368: acc=0.7800, nmi=0.8865\n",
      "stage3\n",
      "Epoch 369: acc=0.8025, nmi=0.8960\n",
      "stage3\n",
      "Epoch 370: acc=0.8000, nmi=0.8908\n",
      "stage3\n",
      "Epoch 371: acc=0.7925, nmi=0.8835\n",
      "stage3\n",
      "Epoch 372: acc=0.8075, nmi=0.8906\n",
      "stage3\n",
      "Epoch 373: acc=0.7850, nmi=0.8884\n",
      "stage3\n",
      "Epoch 374: acc=0.7875, nmi=0.8881\n",
      "stage3\n",
      "Epoch 375: acc=0.7850, nmi=0.8855\n",
      "stage3\n",
      "Epoch 376: acc=0.7900, nmi=0.8918\n",
      "stage3\n",
      "Epoch 377: acc=0.7800, nmi=0.8859\n",
      "stage3\n",
      "Epoch 378: acc=0.7925, nmi=0.8882\n",
      "stage3\n",
      "Epoch 379: acc=0.8075, nmi=0.8840\n",
      "stage3\n",
      "Epoch 380: acc=0.8025, nmi=0.8918\n",
      "stage3\n",
      "Epoch 381: acc=0.8075, nmi=0.8913\n",
      "stage3\n",
      "Epoch 382: acc=0.8050, nmi=0.8900\n",
      "stage3\n",
      "Epoch 383: acc=0.8125, nmi=0.8932\n",
      "stage3\n",
      "Epoch 384: acc=0.8050, nmi=0.8951\n",
      "stage3\n",
      "Epoch 385: acc=0.8150, nmi=0.8959\n",
      "stage3\n",
      "Epoch 386: acc=0.8050, nmi=0.8932\n",
      "stage3\n",
      "Epoch 387: acc=0.8100, nmi=0.8941\n",
      "stage3\n",
      "Epoch 388: acc=0.8075, nmi=0.8923\n",
      "stage3\n",
      "Epoch 389: acc=0.8050, nmi=0.8874\n",
      "stage3\n",
      "Epoch 390: acc=0.8150, nmi=0.8971\n",
      "stage3\n",
      "Epoch 391: acc=0.8125, nmi=0.8950\n",
      "stage3\n",
      "Epoch 392: acc=0.8150, nmi=0.8946\n",
      "stage3\n",
      "Epoch 393: acc=0.8200, nmi=0.8997\n",
      "stage3\n",
      "Epoch 394: acc=0.8175, nmi=0.8975\n",
      "stage3\n",
      "Epoch 395: acc=0.8050, nmi=0.8963\n",
      "stage3\n",
      "Epoch 396: acc=0.8100, nmi=0.8970\n",
      "stage3\n",
      "Epoch 397: acc=0.8075, nmi=0.8911\n",
      "stage3\n",
      "Epoch 398: acc=0.8100, nmi=0.8913\n",
      "stage3\n",
      "Epoch 399: acc=0.8050, nmi=0.8892\n",
      "stage3\n",
      "Epoch 400: acc=0.8125, nmi=0.8991\n",
      "stage3\n",
      "Epoch 401: acc=0.8125, nmi=0.9006\n",
      "stage3\n",
      "Epoch 402: acc=0.8100, nmi=0.8956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage3\n",
      "Epoch 403: acc=0.8150, nmi=0.8971\n",
      "stage3\n",
      "Epoch 404: acc=0.8125, nmi=0.8956\n",
      "stage3\n",
      "Epoch 405: acc=0.8300, nmi=0.9077\n",
      "stage3\n",
      "Epoch 406: acc=0.8275, nmi=0.9048\n",
      "stage3\n",
      "Epoch 407: acc=0.8350, nmi=0.9107\n",
      "stage3\n",
      "Epoch 408: acc=0.8375, nmi=0.9092\n",
      "stage3\n",
      "Epoch 409: acc=0.8300, nmi=0.9089\n",
      "stage3\n",
      "Epoch 410: acc=0.8375, nmi=0.9103\n",
      "stage3\n",
      "Epoch 411: acc=0.8475, nmi=0.9107\n",
      "stage3\n",
      "Epoch 412: acc=0.8275, nmi=0.9128\n",
      "stage3\n",
      "Epoch 413: acc=0.8200, nmi=0.9054\n",
      "stage3\n",
      "Epoch 414: acc=0.8275, nmi=0.9087\n",
      "stage3\n",
      "Epoch 415: acc=0.8125, nmi=0.8988\n",
      "stage3\n",
      "Epoch 416: acc=0.8225, nmi=0.9054\n",
      "stage3\n",
      "Epoch 417: acc=0.8325, nmi=0.9083\n",
      "stage3\n",
      "Epoch 418: acc=0.8375, nmi=0.9164\n",
      "stage3\n",
      "Epoch 419: acc=0.8275, nmi=0.9039\n",
      "stage3\n",
      "Epoch 420: acc=0.8375, nmi=0.9117\n",
      "stage3\n",
      "Epoch 421: acc=0.8325, nmi=0.9083\n",
      "stage3\n",
      "Epoch 422: acc=0.8400, nmi=0.9125\n",
      "stage3\n",
      "Epoch 423: acc=0.8150, nmi=0.8972\n",
      "stage3\n",
      "Epoch 424: acc=0.8200, nmi=0.9001\n",
      "stage3\n",
      "Epoch 425: acc=0.8200, nmi=0.9001\n",
      "stage3\n",
      "Epoch 426: acc=0.8250, nmi=0.9059\n",
      "stage3\n",
      "Epoch 427: acc=0.8225, nmi=0.9078\n",
      "stage3\n",
      "Epoch 428: acc=0.8325, nmi=0.9124\n",
      "stage3\n",
      "Epoch 429: acc=0.8300, nmi=0.9103\n",
      "stage3\n",
      "Epoch 430: acc=0.8200, nmi=0.9068\n",
      "stage3\n",
      "Epoch 431: acc=0.8425, nmi=0.9155\n",
      "stage3\n",
      "Epoch 432: acc=0.8325, nmi=0.9119\n",
      "stage3\n",
      "Epoch 433: acc=0.8300, nmi=0.9098\n",
      "stage3\n",
      "Epoch 434: acc=0.8550, nmi=0.9216\n",
      "stage3\n",
      "Epoch 435: acc=0.8375, nmi=0.9117\n",
      "stage3\n",
      "Epoch 436: acc=0.8375, nmi=0.9099\n",
      "stage3\n",
      "Epoch 437: acc=0.8300, nmi=0.9126\n",
      "stage3\n",
      "Epoch 438: acc=0.8300, nmi=0.9105\n",
      "stage3\n",
      "Epoch 439: acc=0.8300, nmi=0.9120\n",
      "stage3\n",
      "Epoch 440: acc=0.8275, nmi=0.9087\n",
      "stage3\n",
      "Epoch 441: acc=0.8375, nmi=0.9125\n",
      "stage3\n",
      "Epoch 442: acc=0.8450, nmi=0.9156\n",
      "stage3\n",
      "Epoch 443: acc=0.8400, nmi=0.9144\n",
      "stage3\n",
      "Epoch 444: acc=0.8525, nmi=0.9245\n",
      "stage3\n",
      "Epoch 445: acc=0.8325, nmi=0.9142\n",
      "stage3\n",
      "Epoch 446: acc=0.8400, nmi=0.9132\n",
      "stage3\n",
      "Epoch 447: acc=0.8425, nmi=0.9153\n",
      "stage3\n",
      "Epoch 448: acc=0.8425, nmi=0.9096\n",
      "stage3\n",
      "Epoch 449: acc=0.8275, nmi=0.9039\n",
      "stage3\n",
      "Epoch 450: acc=0.8400, nmi=0.9130\n",
      "stage3\n",
      "Epoch 451: acc=0.8325, nmi=0.9129\n",
      "stage3\n",
      "Epoch 452: acc=0.8200, nmi=0.9122\n",
      "stage3\n",
      "Epoch 453: acc=0.8175, nmi=0.9019\n",
      "stage3\n",
      "Epoch 454: acc=0.8225, nmi=0.9099\n",
      "stage3\n",
      "Epoch 455: acc=0.8175, nmi=0.9074\n",
      "stage3\n",
      "Epoch 456: acc=0.8225, nmi=0.9091\n",
      "stage3\n",
      "Epoch 457: acc=0.8475, nmi=0.9155\n",
      "stage3\n",
      "Epoch 458: acc=0.8475, nmi=0.9145\n",
      "stage3\n",
      "Epoch 459: acc=0.8225, nmi=0.9156\n",
      "stage3\n",
      "Epoch 460: acc=0.8400, nmi=0.9196\n",
      "stage3\n",
      "Epoch 461: acc=0.8325, nmi=0.9124\n",
      "stage3\n",
      "Epoch 462: acc=0.8325, nmi=0.9135\n",
      "stage3\n",
      "Epoch 463: acc=0.8350, nmi=0.9188\n",
      "stage3\n",
      "Epoch 464: acc=0.8400, nmi=0.9185\n",
      "stage3\n",
      "Epoch 465: acc=0.8450, nmi=0.9203\n",
      "stage3\n",
      "Epoch 466: acc=0.8350, nmi=0.9164\n",
      "stage3\n",
      "Epoch 467: acc=0.8450, nmi=0.9205\n",
      "stage3\n",
      "Epoch 468: acc=0.8525, nmi=0.9223\n",
      "stage3\n",
      "Epoch 469: acc=0.8525, nmi=0.9199\n",
      "stage3\n",
      "Epoch 470: acc=0.8525, nmi=0.9246\n",
      "stage3\n",
      "Epoch 471: acc=0.8450, nmi=0.9180\n",
      "stage3\n",
      "Epoch 472: acc=0.8475, nmi=0.9201\n",
      "stage3\n",
      "Epoch 473: acc=0.8450, nmi=0.9173\n",
      "stage3\n",
      "Epoch 474: acc=0.8325, nmi=0.9175\n",
      "stage3\n",
      "Epoch 475: acc=0.8675, nmi=0.9279\n",
      "stage3\n",
      "Epoch 476: acc=0.8450, nmi=0.9146\n",
      "stage3\n",
      "Epoch 477: acc=0.8375, nmi=0.9140\n",
      "stage3\n",
      "Epoch 478: acc=0.8575, nmi=0.9185\n",
      "stage3\n",
      "Epoch 479: acc=0.8450, nmi=0.9154\n",
      "stage3\n",
      "Epoch 480: acc=0.8500, nmi=0.9176\n",
      "stage3\n",
      "Epoch 481: acc=0.8400, nmi=0.9164\n",
      "stage3\n",
      "Epoch 482: acc=0.8525, nmi=0.9161\n",
      "stage3\n",
      "Epoch 483: acc=0.8650, nmi=0.9231\n",
      "stage3\n",
      "Epoch 484: acc=0.8525, nmi=0.9233\n",
      "stage3\n",
      "Epoch 485: acc=0.8525, nmi=0.9217\n",
      "stage3\n",
      "Epoch 486: acc=0.8675, nmi=0.9265\n",
      "stage3\n",
      "Epoch 487: acc=0.8500, nmi=0.9274\n",
      "stage3\n",
      "Epoch 488: acc=0.8675, nmi=0.9287\n",
      "stage3\n",
      "Epoch 489: acc=0.8650, nmi=0.9253\n",
      "stage3\n",
      "Epoch 490: acc=0.8425, nmi=0.9133\n",
      "stage3\n",
      "Epoch 491: acc=0.8650, nmi=0.9232\n",
      "stage3\n",
      "Epoch 492: acc=0.8650, nmi=0.9222\n",
      "stage3\n",
      "Epoch 493: acc=0.8625, nmi=0.9224\n",
      "stage3\n",
      "Epoch 494: acc=0.8600, nmi=0.9205\n",
      "stage3\n",
      "Epoch 495: acc=0.8600, nmi=0.9199\n",
      "stage3\n",
      "Epoch 496: acc=0.8625, nmi=0.9205\n",
      "stage3\n",
      "Epoch 497: acc=0.8650, nmi=0.9261\n",
      "stage3\n",
      "Epoch 498: acc=0.8625, nmi=0.9225\n",
      "stage3\n",
      "Epoch 499: acc=0.8400, nmi=0.9148\n",
      "stage3\n",
      "Epoch 500: acc=0.8375, nmi=0.9169\n",
      "stage3\n",
      "Epoch 501: acc=0.8500, nmi=0.9170\n",
      "stage3\n",
      "Epoch 502: acc=0.8325, nmi=0.9184\n",
      "stage3\n",
      "Epoch 503: acc=0.8325, nmi=0.9148\n",
      "stage3\n",
      "Epoch 504: acc=0.8325, nmi=0.9163\n",
      "stage3\n",
      "Epoch 505: acc=0.8300, nmi=0.9126\n",
      "stage3\n",
      "Epoch 506: acc=0.8300, nmi=0.9126\n",
      "stage3\n",
      "Epoch 507: acc=0.8350, nmi=0.9169\n",
      "stage3\n",
      "Epoch 508: acc=0.8325, nmi=0.9148\n",
      "stage3\n",
      "Epoch 509: acc=0.8250, nmi=0.9130\n",
      "stage3\n",
      "Epoch 510: acc=0.8325, nmi=0.9148\n",
      "stage3\n",
      "Epoch 511: acc=0.8300, nmi=0.9116\n",
      "stage3\n",
      "Epoch 512: acc=0.8300, nmi=0.9116\n",
      "stage3\n",
      "Epoch 513: acc=0.8300, nmi=0.9115\n",
      "stage3\n",
      "Epoch 514: acc=0.8275, nmi=0.9130\n",
      "stage3\n",
      "Epoch 515: acc=0.8400, nmi=0.9164\n",
      "stage3\n",
      "Epoch 516: acc=0.8300, nmi=0.9129\n",
      "stage3\n",
      "Epoch 517: acc=0.8300, nmi=0.9131\n",
      "stage3\n",
      "Epoch 518: acc=0.8425, nmi=0.9183\n",
      "stage3\n",
      "Epoch 519: acc=0.8400, nmi=0.9177\n",
      "stage3\n",
      "Epoch 520: acc=0.8325, nmi=0.9191\n",
      "stage3\n",
      "Epoch 521: acc=0.8300, nmi=0.9145\n",
      "stage3\n",
      "Epoch 522: acc=0.8325, nmi=0.9176\n",
      "stage3\n",
      "Epoch 523: acc=0.8350, nmi=0.9178\n",
      "stage3\n",
      "Epoch 524: acc=0.8300, nmi=0.9135\n",
      "stage3\n",
      "Epoch 525: acc=0.8325, nmi=0.9146\n",
      "stage3\n",
      "Epoch 526: acc=0.8425, nmi=0.9176\n",
      "stage3\n",
      "Epoch 527: acc=0.8425, nmi=0.9205\n",
      "stage3\n",
      "Epoch 528: acc=0.8525, nmi=0.9241\n",
      "stage3\n",
      "Epoch 529: acc=0.8550, nmi=0.9254\n",
      "stage3\n",
      "Epoch 530: acc=0.8425, nmi=0.9229\n",
      "stage3\n",
      "Epoch 531: acc=0.8200, nmi=0.9079\n",
      "stage3\n",
      "Epoch 532: acc=0.8400, nmi=0.9181\n",
      "stage3\n",
      "Epoch 533: acc=0.8400, nmi=0.9152\n",
      "stage3\n",
      "Epoch 534: acc=0.8400, nmi=0.9197\n",
      "stage3\n",
      "Epoch 535: acc=0.8375, nmi=0.9186\n",
      "stage3\n",
      "Epoch 536: acc=0.8425, nmi=0.9216\n",
      "stage3\n",
      "Epoch 537: acc=0.8300, nmi=0.9118\n",
      "stage3\n",
      "Epoch 538: acc=0.8525, nmi=0.9175\n",
      "stage3\n",
      "Epoch 539: acc=0.8400, nmi=0.9192\n",
      "stage3\n",
      "Epoch 540: acc=0.8350, nmi=0.9140\n",
      "stage3\n",
      "Epoch 541: acc=0.8350, nmi=0.9138\n",
      "stage3\n",
      "Epoch 542: acc=0.8400, nmi=0.9172\n",
      "stage3\n",
      "Epoch 543: acc=0.8200, nmi=0.9058\n",
      "stage3\n",
      "Epoch 544: acc=0.8275, nmi=0.9167\n",
      "stage3\n",
      "Epoch 545: acc=0.8250, nmi=0.9127\n",
      "stage3\n",
      "Epoch 546: acc=0.8275, nmi=0.9117\n",
      "stage3\n",
      "Epoch 547: acc=0.8125, nmi=0.9051\n",
      "stage3\n",
      "Epoch 548: acc=0.8275, nmi=0.9146\n",
      "stage3\n",
      "Epoch 549: acc=0.8425, nmi=0.9143\n",
      "stage3\n",
      "Epoch 550: acc=0.8350, nmi=0.9171\n",
      "stage3\n",
      "Epoch 551: acc=0.8475, nmi=0.9218\n",
      "stage3\n",
      "Epoch 552: acc=0.8450, nmi=0.9195\n",
      "stage3\n",
      "Epoch 553: acc=0.8375, nmi=0.9136\n",
      "stage3\n",
      "Epoch 554: acc=0.8450, nmi=0.9217\n",
      "stage3\n",
      "Epoch 555: acc=0.8500, nmi=0.9212\n",
      "stage3\n",
      "Epoch 556: acc=0.8400, nmi=0.9182\n",
      "stage3\n",
      "Epoch 557: acc=0.8475, nmi=0.9184\n",
      "stage3\n",
      "Epoch 558: acc=0.8650, nmi=0.9234\n",
      "stage3\n",
      "Epoch 559: acc=0.8500, nmi=0.9249\n",
      "stage3\n",
      "Epoch 560: acc=0.8500, nmi=0.9233\n",
      "stage3\n",
      "Epoch 561: acc=0.8500, nmi=0.9232\n",
      "stage3\n",
      "Epoch 562: acc=0.8525, nmi=0.9263\n",
      "stage3\n",
      "Epoch 563: acc=0.8450, nmi=0.9176\n",
      "stage3\n",
      "Epoch 564: acc=0.8550, nmi=0.9272\n",
      "stage3\n",
      "Epoch 565: acc=0.8475, nmi=0.9208\n",
      "stage3\n",
      "Epoch 566: acc=0.8550, nmi=0.9279\n",
      "stage3\n",
      "Epoch 567: acc=0.8600, nmi=0.9256\n",
      "stage3\n",
      "Epoch 568: acc=0.8575, nmi=0.9284\n",
      "stage3\n",
      "Epoch 569: acc=0.8750, nmi=0.9341\n",
      "stage3\n",
      "Epoch 570: acc=0.8500, nmi=0.9260\n",
      "stage3\n",
      "Epoch 571: acc=0.8700, nmi=0.9331\n",
      "stage3\n",
      "Epoch 572: acc=0.8475, nmi=0.9260\n",
      "stage3\n",
      "Epoch 573: acc=0.8725, nmi=0.9320\n",
      "stage3\n",
      "Epoch 574: acc=0.8600, nmi=0.9292\n",
      "stage3\n",
      "Epoch 575: acc=0.8800, nmi=0.9356\n",
      "stage3\n",
      "Epoch 576: acc=0.8750, nmi=0.9303\n",
      "stage3\n",
      "Epoch 577: acc=0.8650, nmi=0.9290\n",
      "stage3\n",
      "Epoch 578: acc=0.8575, nmi=0.9271\n",
      "stage3\n",
      "Epoch 579: acc=0.8775, nmi=0.9326\n",
      "stage3\n",
      "Epoch 580: acc=0.8675, nmi=0.9294\n",
      "stage3\n",
      "Epoch 581: acc=0.8800, nmi=0.9358\n",
      "stage3\n",
      "Epoch 582: acc=0.8775, nmi=0.9325\n",
      "stage3\n",
      "Epoch 583: acc=0.8750, nmi=0.9304\n",
      "stage3\n",
      "Epoch 584: acc=0.8800, nmi=0.9357\n",
      "stage3\n",
      "Epoch 585: acc=0.8650, nmi=0.9307\n",
      "stage3\n",
      "Epoch 586: acc=0.8675, nmi=0.9329\n",
      "stage3\n",
      "Epoch 587: acc=0.8825, nmi=0.9369\n",
      "stage3\n",
      "Epoch 588: acc=0.8625, nmi=0.9304\n",
      "stage3\n",
      "Epoch 589: acc=0.8675, nmi=0.9352\n",
      "stage3\n",
      "Epoch 590: acc=0.8600, nmi=0.9278\n",
      "stage3\n",
      "Epoch 591: acc=0.8600, nmi=0.9303\n",
      "stage3\n",
      "Epoch 592: acc=0.8575, nmi=0.9311\n",
      "stage3\n",
      "Epoch 593: acc=0.8475, nmi=0.9275\n",
      "stage3\n",
      "Epoch 594: acc=0.8475, nmi=0.9243\n",
      "stage3\n",
      "Epoch 595: acc=0.8450, nmi=0.9202\n",
      "stage3\n",
      "Epoch 596: acc=0.8500, nmi=0.9226\n",
      "stage3\n",
      "Epoch 597: acc=0.8625, nmi=0.9304\n",
      "stage3\n",
      "Epoch 598: acc=0.8450, nmi=0.9228\n",
      "stage3\n",
      "Epoch 599: acc=0.8475, nmi=0.9249\n",
      "stage3\n",
      "Epoch 600: acc=0.8300, nmi=0.9208\n",
      "stage3\n",
      "Epoch 601: acc=0.8325, nmi=0.9210\n",
      "stage3\n",
      "Epoch 602: acc=0.8400, nmi=0.9216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage3\n",
      "Epoch 603: acc=0.8450, nmi=0.9221\n",
      "stage3\n",
      "Epoch 604: acc=0.8425, nmi=0.9241\n",
      "stage3\n",
      "Epoch 605: acc=0.8425, nmi=0.9211\n",
      "stage3\n",
      "Epoch 606: acc=0.8125, nmi=0.9134\n",
      "stage3\n",
      "Epoch 607: acc=0.8075, nmi=0.9095\n",
      "stage3\n",
      "Epoch 608: acc=0.8300, nmi=0.9208\n",
      "stage3\n",
      "Epoch 609: acc=0.8300, nmi=0.9194\n",
      "stage3\n",
      "Epoch 610: acc=0.8275, nmi=0.9161\n",
      "stage3\n",
      "Epoch 611: acc=0.8075, nmi=0.9103\n",
      "stage3\n",
      "Epoch 612: acc=0.8100, nmi=0.9118\n",
      "stage3\n",
      "Epoch 613: acc=0.8325, nmi=0.9209\n",
      "stage3\n",
      "Epoch 614: acc=0.8175, nmi=0.9119\n",
      "stage3\n",
      "Epoch 615: acc=0.8275, nmi=0.9152\n",
      "stage3\n",
      "Epoch 616: acc=0.8275, nmi=0.9155\n",
      "stage3\n",
      "Epoch 617: acc=0.8275, nmi=0.9164\n",
      "stage3\n",
      "Epoch 618: acc=0.8125, nmi=0.9131\n",
      "stage3\n",
      "Epoch 619: acc=0.8275, nmi=0.9192\n",
      "stage3\n",
      "Epoch 620: acc=0.8150, nmi=0.9135\n",
      "stage3\n",
      "Epoch 621: acc=0.8250, nmi=0.9174\n",
      "stage3\n",
      "Epoch 622: acc=0.8300, nmi=0.9185\n",
      "stage3\n",
      "Epoch 623: acc=0.8225, nmi=0.9119\n",
      "stage3\n",
      "Epoch 624: acc=0.8300, nmi=0.9167\n",
      "stage3\n",
      "Epoch 625: acc=0.8325, nmi=0.9130\n",
      "stage3\n",
      "Epoch 626: acc=0.8350, nmi=0.9166\n",
      "stage3\n",
      "Epoch 627: acc=0.8275, nmi=0.9169\n",
      "stage3\n",
      "Epoch 628: acc=0.8400, nmi=0.9208\n",
      "stage3\n",
      "Epoch 629: acc=0.8250, nmi=0.9182\n",
      "stage3\n",
      "Epoch 630: acc=0.8550, nmi=0.9268\n",
      "stage3\n",
      "Epoch 631: acc=0.8550, nmi=0.9256\n",
      "stage3\n",
      "Epoch 632: acc=0.8550, nmi=0.9261\n",
      "stage3\n",
      "Epoch 633: acc=0.8225, nmi=0.9173\n",
      "stage3\n",
      "Epoch 634: acc=0.8525, nmi=0.9244\n",
      "stage3\n",
      "Epoch 635: acc=0.8525, nmi=0.9242\n",
      "stage3\n",
      "Epoch 636: acc=0.8500, nmi=0.9217\n",
      "stage3\n",
      "Epoch 637: acc=0.8550, nmi=0.9266\n",
      "stage3\n",
      "Epoch 638: acc=0.8525, nmi=0.9268\n",
      "stage3\n",
      "Epoch 639: acc=0.8525, nmi=0.9270\n",
      "stage3\n",
      "Epoch 640: acc=0.8550, nmi=0.9279\n",
      "stage3\n",
      "Epoch 641: acc=0.8550, nmi=0.9289\n",
      "stage3\n",
      "Epoch 642: acc=0.8525, nmi=0.9266\n",
      "stage3\n",
      "Epoch 643: acc=0.8550, nmi=0.9282\n",
      "stage3\n",
      "Epoch 644: acc=0.8500, nmi=0.9231\n",
      "stage3\n",
      "Epoch 645: acc=0.8575, nmi=0.9291\n",
      "stage3\n",
      "Epoch 646: acc=0.8550, nmi=0.9269\n",
      "stage3\n",
      "Epoch 647: acc=0.8550, nmi=0.9269\n",
      "stage3\n",
      "Epoch 648: acc=0.8525, nmi=0.9248\n",
      "stage3\n",
      "Epoch 649: acc=0.8425, nmi=0.9225\n",
      "stage3\n",
      "Epoch 650: acc=0.8500, nmi=0.9232\n",
      "stage3\n",
      "Epoch 651: acc=0.8550, nmi=0.9294\n",
      "stage3\n",
      "Epoch 652: acc=0.8500, nmi=0.9250\n",
      "stage3\n",
      "Epoch 653: acc=0.8525, nmi=0.9246\n",
      "stage3\n",
      "Epoch 654: acc=0.8550, nmi=0.9270\n",
      "stage3\n",
      "Epoch 655: acc=0.8500, nmi=0.9249\n",
      "stage3\n",
      "Epoch 656: acc=0.8550, nmi=0.9263\n",
      "stage3\n",
      "Epoch 657: acc=0.8475, nmi=0.9242\n",
      "stage3\n",
      "Epoch 658: acc=0.8575, nmi=0.9303\n",
      "stage3\n",
      "Epoch 659: acc=0.8450, nmi=0.9212\n",
      "stage3\n",
      "Epoch 660: acc=0.8450, nmi=0.9212\n",
      "stage3\n",
      "Epoch 661: acc=0.8575, nmi=0.9298\n",
      "stage3\n",
      "Epoch 662: acc=0.8575, nmi=0.9281\n",
      "stage3\n",
      "Epoch 663: acc=0.8600, nmi=0.9301\n",
      "stage3\n",
      "Epoch 664: acc=0.8475, nmi=0.9221\n",
      "stage3\n",
      "Epoch 665: acc=0.8350, nmi=0.9202\n",
      "stage3\n",
      "Epoch 666: acc=0.8500, nmi=0.9234\n",
      "stage3\n",
      "Epoch 667: acc=0.8525, nmi=0.9278\n",
      "stage3\n",
      "Epoch 668: acc=0.8550, nmi=0.9277\n",
      "stage3\n",
      "Epoch 669: acc=0.8550, nmi=0.9270\n",
      "stage3\n",
      "Epoch 670: acc=0.8500, nmi=0.9247\n",
      "stage3\n",
      "Epoch 671: acc=0.8525, nmi=0.9254\n",
      "stage3\n",
      "Epoch 672: acc=0.8475, nmi=0.9234\n",
      "stage3\n",
      "Epoch 673: acc=0.8600, nmi=0.9312\n",
      "stage3\n",
      "Epoch 674: acc=0.8850, nmi=0.9351\n",
      "stage3\n",
      "Epoch 675: acc=0.8600, nmi=0.9324\n",
      "stage3\n",
      "Epoch 676: acc=0.8550, nmi=0.9264\n",
      "stage3\n",
      "Epoch 677: acc=0.8600, nmi=0.9325\n",
      "stage3\n",
      "Epoch 678: acc=0.8600, nmi=0.9316\n",
      "stage3\n",
      "Epoch 679: acc=0.8600, nmi=0.9301\n",
      "stage3\n",
      "Epoch 680: acc=0.8625, nmi=0.9322\n",
      "stage3\n",
      "Epoch 681: acc=0.8600, nmi=0.9325\n",
      "stage3\n",
      "Epoch 682: acc=0.8950, nmi=0.9417\n",
      "stage3\n",
      "Epoch 683: acc=0.8675, nmi=0.9348\n",
      "stage3\n",
      "Epoch 684: acc=0.8700, nmi=0.9396\n",
      "stage3\n",
      "Epoch 685: acc=0.8625, nmi=0.9338\n",
      "stage3\n",
      "Epoch 686: acc=0.8700, nmi=0.9396\n",
      "stage3\n",
      "Epoch 687: acc=0.8650, nmi=0.9337\n",
      "stage3\n",
      "Epoch 688: acc=0.8825, nmi=0.9352\n",
      "stage3\n",
      "Epoch 689: acc=0.8625, nmi=0.9339\n",
      "stage3\n",
      "Epoch 690: acc=0.8675, nmi=0.9374\n",
      "stage3\n",
      "Epoch 691: acc=0.8925, nmi=0.9398\n",
      "stage3\n",
      "Epoch 692: acc=0.8825, nmi=0.9388\n",
      "stage3\n",
      "Epoch 693: acc=0.8900, nmi=0.9409\n",
      "stage3\n",
      "Epoch 694: acc=0.8850, nmi=0.9398\n",
      "stage3\n",
      "Epoch 695: acc=0.8925, nmi=0.9398\n",
      "stage3\n",
      "Epoch 696: acc=0.8950, nmi=0.9435\n",
      "stage3\n",
      "Epoch 697: acc=0.8850, nmi=0.9380\n",
      "stage3\n",
      "Epoch 698: acc=0.8700, nmi=0.9385\n",
      "stage3\n",
      "Epoch 699: acc=0.8700, nmi=0.9380\n",
      "stage3\n",
      "Epoch 700: acc=0.8650, nmi=0.9361\n",
      "stage3\n",
      "Epoch 701: acc=0.8600, nmi=0.9332\n",
      "stage3\n",
      "Epoch 702: acc=0.8675, nmi=0.9367\n",
      "stage3\n",
      "Epoch 703: acc=0.8700, nmi=0.9380\n",
      "stage3\n",
      "Epoch 704: acc=0.8625, nmi=0.9322\n",
      "stage3\n",
      "Epoch 705: acc=0.8650, nmi=0.9344\n",
      "stage3\n",
      "Epoch 706: acc=0.8650, nmi=0.9361\n",
      "stage3\n",
      "Epoch 707: acc=0.8575, nmi=0.9330\n",
      "stage3\n",
      "Epoch 708: acc=0.8575, nmi=0.9330\n",
      "stage3\n",
      "Epoch 709: acc=0.8575, nmi=0.9330\n",
      "stage3\n",
      "Epoch 710: acc=0.8575, nmi=0.9330\n",
      "stage3\n",
      "Epoch 711: acc=0.8625, nmi=0.9335\n",
      "stage3\n",
      "Epoch 712: acc=0.8475, nmi=0.9272\n",
      "stage3\n",
      "Epoch 713: acc=0.8575, nmi=0.9301\n",
      "stage3\n",
      "Epoch 714: acc=0.8625, nmi=0.9357\n",
      "stage3\n",
      "Epoch 715: acc=0.8575, nmi=0.9275\n",
      "stage3\n",
      "Epoch 716: acc=0.8575, nmi=0.9314\n",
      "stage3\n",
      "Epoch 717: acc=0.8575, nmi=0.9330\n",
      "stage3\n",
      "Epoch 718: acc=0.8450, nmi=0.9281\n",
      "stage3\n",
      "Epoch 719: acc=0.8625, nmi=0.9348\n",
      "stage3\n",
      "Epoch 720: acc=0.8675, nmi=0.9361\n",
      "stage3\n",
      "Epoch 721: acc=0.8675, nmi=0.9383\n",
      "stage3\n",
      "Epoch 722: acc=0.8925, nmi=0.9406\n",
      "stage3\n",
      "Epoch 723: acc=0.8925, nmi=0.9406\n",
      "stage3\n",
      "Epoch 724: acc=0.8575, nmi=0.9298\n",
      "stage3\n",
      "Epoch 725: acc=0.8875, nmi=0.9380\n",
      "stage3\n",
      "Epoch 726: acc=0.8575, nmi=0.9298\n",
      "stage3\n",
      "Epoch 727: acc=0.8425, nmi=0.9258\n",
      "stage3\n",
      "Epoch 728: acc=0.8550, nmi=0.9278\n",
      "stage3\n",
      "Epoch 729: acc=0.8550, nmi=0.9294\n",
      "stage3\n",
      "Epoch 730: acc=0.8575, nmi=0.9301\n",
      "stage3\n",
      "Epoch 731: acc=0.8575, nmi=0.9301\n",
      "stage3\n",
      "Epoch 732: acc=0.8575, nmi=0.9301\n",
      "stage3\n",
      "Epoch 733: acc=0.8450, nmi=0.9267\n",
      "stage3\n",
      "Epoch 734: acc=0.8550, nmi=0.9278\n",
      "stage3\n",
      "Epoch 735: acc=0.8550, nmi=0.9279\n",
      "stage3\n",
      "Epoch 736: acc=0.8475, nmi=0.9240\n",
      "stage3\n",
      "Epoch 737: acc=0.8575, nmi=0.9317\n",
      "stage3\n",
      "Epoch 738: acc=0.8425, nmi=0.9256\n",
      "stage3\n",
      "Epoch 739: acc=0.8675, nmi=0.9301\n",
      "stage3\n",
      "Epoch 740: acc=0.8425, nmi=0.9245\n",
      "stage3\n",
      "Epoch 741: acc=0.8575, nmi=0.9301\n",
      "stage3\n",
      "Epoch 742: acc=0.8550, nmi=0.9279\n",
      "stage3\n",
      "Epoch 743: acc=0.8650, nmi=0.9276\n",
      "stage3\n",
      "Epoch 744: acc=0.8550, nmi=0.9277\n",
      "stage3\n",
      "Epoch 745: acc=0.8600, nmi=0.9249\n",
      "stage3\n",
      "Epoch 746: acc=0.8700, nmi=0.9302\n",
      "stage3\n",
      "Epoch 747: acc=0.8525, nmi=0.9243\n",
      "stage3\n",
      "Epoch 748: acc=0.8875, nmi=0.9361\n",
      "stage3\n",
      "Epoch 749: acc=0.8500, nmi=0.9258\n",
      "stage3\n",
      "Epoch 750: acc=0.8675, nmi=0.9313\n",
      "stage3\n",
      "Epoch 751: acc=0.8525, nmi=0.9273\n",
      "stage3\n",
      "Epoch 752: acc=0.8375, nmi=0.9245\n",
      "stage3\n",
      "Epoch 753: acc=0.8550, nmi=0.9293\n",
      "stage3\n",
      "Epoch 754: acc=0.8825, nmi=0.9376\n",
      "stage3\n",
      "Epoch 755: acc=0.8500, nmi=0.9257\n",
      "stage3\n",
      "Epoch 756: acc=0.8825, nmi=0.9370\n",
      "stage3\n",
      "Epoch 757: acc=0.8575, nmi=0.9272\n",
      "stage3\n",
      "Epoch 758: acc=0.8725, nmi=0.9357\n",
      "stage3\n",
      "Epoch 759: acc=0.8600, nmi=0.9333\n",
      "stage3\n",
      "Epoch 760: acc=0.8375, nmi=0.9228\n",
      "stage3\n",
      "Epoch 761: acc=0.8500, nmi=0.9269\n",
      "stage3\n",
      "Epoch 762: acc=0.8600, nmi=0.9326\n",
      "stage3\n",
      "Epoch 763: acc=0.8525, nmi=0.9259\n",
      "stage3\n",
      "Epoch 764: acc=0.8550, nmi=0.9282\n",
      "stage3\n",
      "Epoch 765: acc=0.8525, nmi=0.9269\n",
      "stage3\n",
      "Epoch 766: acc=0.8525, nmi=0.9282\n",
      "stage3\n",
      "Epoch 767: acc=0.8500, nmi=0.9243\n",
      "stage3\n",
      "Epoch 768: acc=0.8550, nmi=0.9308\n",
      "stage3\n",
      "Epoch 769: acc=0.8550, nmi=0.9290\n",
      "stage3\n",
      "Epoch 770: acc=0.8550, nmi=0.9265\n",
      "stage3\n",
      "Epoch 771: acc=0.8700, nmi=0.9310\n",
      "stage3\n",
      "Epoch 772: acc=0.8675, nmi=0.9300\n",
      "stage3\n",
      "Epoch 773: acc=0.8700, nmi=0.9306\n",
      "stage3\n",
      "Epoch 774: acc=0.8750, nmi=0.9351\n",
      "stage3\n",
      "Epoch 775: acc=0.8700, nmi=0.9310\n",
      "stage3\n",
      "Epoch 776: acc=0.8525, nmi=0.9285\n",
      "stage3\n",
      "Epoch 777: acc=0.8725, nmi=0.9333\n",
      "stage3\n",
      "Epoch 778: acc=0.8725, nmi=0.9328\n",
      "stage3\n",
      "Epoch 779: acc=0.8600, nmi=0.9317\n",
      "stage3\n",
      "Epoch 780: acc=0.8625, nmi=0.9348\n",
      "stage3\n",
      "Epoch 781: acc=0.8675, nmi=0.9288\n",
      "stage3\n",
      "Epoch 782: acc=0.8700, nmi=0.9306\n",
      "stage3\n",
      "Epoch 783: acc=0.8625, nmi=0.9305\n",
      "stage3\n",
      "Epoch 784: acc=0.8825, nmi=0.9339\n",
      "stage3\n",
      "Epoch 785: acc=0.8625, nmi=0.9347\n",
      "stage3\n",
      "Epoch 786: acc=0.8475, nmi=0.9201\n",
      "stage3\n",
      "Epoch 787: acc=0.8575, nmi=0.9255\n",
      "stage3\n",
      "Epoch 788: acc=0.8625, nmi=0.9304\n",
      "stage3\n",
      "Epoch 789: acc=0.8675, nmi=0.9286\n",
      "stage3\n",
      "Epoch 790: acc=0.8675, nmi=0.9264\n",
      "stage3\n",
      "Epoch 791: acc=0.8625, nmi=0.9303\n",
      "stage3\n",
      "Epoch 792: acc=0.8575, nmi=0.9256\n",
      "stage3\n",
      "Epoch 793: acc=0.8500, nmi=0.9214\n",
      "stage3\n",
      "Epoch 794: acc=0.8775, nmi=0.9331\n",
      "stage3\n",
      "Epoch 795: acc=0.8675, nmi=0.9334\n",
      "stage3\n",
      "Epoch 796: acc=0.8625, nmi=0.9315\n",
      "stage3\n",
      "Epoch 797: acc=0.8600, nmi=0.9294\n",
      "stage3\n",
      "Epoch 798: acc=0.8525, nmi=0.9224\n",
      "stage3\n",
      "Epoch 799: acc=0.8650, nmi=0.9312\n",
      "stage3\n",
      "Epoch 800: acc=0.8550, nmi=0.9244\n",
      "stage3\n",
      "Epoch 801: acc=0.8675, nmi=0.9314\n",
      "stage3\n",
      "Epoch 802: acc=0.8675, nmi=0.9285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage3\n",
      "Epoch 803: acc=0.8650, nmi=0.9221\n",
      "stage3\n",
      "Epoch 804: acc=0.8525, nmi=0.9173\n",
      "stage3\n",
      "Epoch 805: acc=0.8525, nmi=0.9159\n",
      "stage3\n",
      "Epoch 806: acc=0.8675, nmi=0.9278\n",
      "stage3\n",
      "Epoch 807: acc=0.8750, nmi=0.9286\n",
      "stage3\n",
      "Epoch 808: acc=0.8700, nmi=0.9278\n",
      "stage3\n",
      "Epoch 809: acc=0.8500, nmi=0.9197\n",
      "stage3\n",
      "Epoch 810: acc=0.8800, nmi=0.9268\n",
      "stage3\n",
      "Epoch 811: acc=0.8675, nmi=0.9308\n",
      "stage3\n",
      "Epoch 812: acc=0.8450, nmi=0.9191\n",
      "stage3\n",
      "Epoch 813: acc=0.8550, nmi=0.9163\n",
      "stage3\n",
      "Epoch 814: acc=0.8525, nmi=0.9229\n",
      "stage3\n",
      "Epoch 815: acc=0.8425, nmi=0.9248\n",
      "stage3\n",
      "Epoch 816: acc=0.8650, nmi=0.9342\n",
      "stage3\n",
      "Epoch 817: acc=0.8575, nmi=0.9282\n",
      "stage3\n",
      "Epoch 818: acc=0.8600, nmi=0.9317\n",
      "stage3\n",
      "Epoch 819: acc=0.8625, nmi=0.9319\n",
      "stage3\n",
      "Epoch 820: acc=0.8600, nmi=0.9304\n",
      "stage3\n",
      "Epoch 821: acc=0.8500, nmi=0.9238\n",
      "stage3\n",
      "Epoch 822: acc=0.8500, nmi=0.9262\n",
      "stage3\n",
      "Epoch 823: acc=0.8550, nmi=0.9264\n",
      "stage3\n",
      "Epoch 824: acc=0.8575, nmi=0.9295\n",
      "stage3\n",
      "Epoch 825: acc=0.8500, nmi=0.9240\n",
      "stage3\n",
      "Epoch 826: acc=0.8500, nmi=0.9231\n",
      "stage3\n",
      "Epoch 827: acc=0.8475, nmi=0.9226\n",
      "stage3\n",
      "Epoch 828: acc=0.8475, nmi=0.9212\n",
      "stage3\n",
      "Epoch 829: acc=0.8525, nmi=0.9270\n",
      "stage3\n",
      "Epoch 830: acc=0.8450, nmi=0.9202\n",
      "stage3\n",
      "Epoch 831: acc=0.8500, nmi=0.9219\n",
      "stage3\n",
      "Epoch 832: acc=0.8500, nmi=0.9233\n",
      "stage3\n",
      "Epoch 833: acc=0.8300, nmi=0.9159\n",
      "stage3\n",
      "Epoch 834: acc=0.8175, nmi=0.9131\n",
      "stage3\n",
      "Epoch 835: acc=0.8475, nmi=0.9183\n",
      "stage3\n",
      "Epoch 836: acc=0.8475, nmi=0.9204\n",
      "stage3\n",
      "Epoch 837: acc=0.8500, nmi=0.9206\n",
      "stage3\n",
      "Epoch 838: acc=0.8375, nmi=0.9118\n",
      "stage3\n",
      "Epoch 839: acc=0.8400, nmi=0.9140\n",
      "stage3\n",
      "Epoch 840: acc=0.8425, nmi=0.9175\n",
      "stage3\n",
      "Epoch 841: acc=0.8275, nmi=0.9139\n",
      "stage3\n",
      "Epoch 842: acc=0.8425, nmi=0.9145\n",
      "stage3\n",
      "Epoch 843: acc=0.8375, nmi=0.9117\n",
      "stage3\n",
      "Epoch 844: acc=0.8400, nmi=0.9142\n",
      "stage3\n",
      "Epoch 845: acc=0.8275, nmi=0.9116\n",
      "stage3\n",
      "Epoch 846: acc=0.8425, nmi=0.9194\n",
      "stage3\n",
      "Epoch 847: acc=0.8400, nmi=0.9142\n",
      "stage3\n",
      "Epoch 848: acc=0.8400, nmi=0.9096\n",
      "stage3\n",
      "Epoch 849: acc=0.8425, nmi=0.9183\n",
      "stage3\n",
      "Epoch 850: acc=0.8475, nmi=0.9193\n",
      "stage3\n",
      "Epoch 851: acc=0.8400, nmi=0.9142\n",
      "stage3\n",
      "Epoch 852: acc=0.8425, nmi=0.9165\n",
      "stage3\n",
      "Epoch 853: acc=0.8375, nmi=0.9155\n",
      "stage3\n",
      "Epoch 854: acc=0.8375, nmi=0.9107\n",
      "stage3\n",
      "Epoch 855: acc=0.8450, nmi=0.9197\n",
      "stage3\n",
      "Epoch 856: acc=0.8425, nmi=0.9155\n",
      "stage3\n",
      "Epoch 857: acc=0.8375, nmi=0.9144\n",
      "stage3\n",
      "Epoch 858: acc=0.8400, nmi=0.9142\n",
      "stage3\n",
      "Epoch 859: acc=0.8450, nmi=0.9190\n",
      "stage3\n",
      "Epoch 860: acc=0.8400, nmi=0.9168\n",
      "stage3\n",
      "Epoch 861: acc=0.8400, nmi=0.9161\n",
      "stage3\n",
      "Epoch 862: acc=0.8375, nmi=0.9117\n",
      "stage3\n",
      "Epoch 863: acc=0.8625, nmi=0.9251\n",
      "stage3\n",
      "Epoch 864: acc=0.8400, nmi=0.9129\n",
      "stage3\n",
      "Epoch 865: acc=0.8700, nmi=0.9298\n",
      "stage3\n",
      "Epoch 866: acc=0.8400, nmi=0.9128\n",
      "stage3\n",
      "Epoch 867: acc=0.8625, nmi=0.9235\n",
      "stage3\n",
      "Epoch 868: acc=0.8750, nmi=0.9298\n",
      "stage3\n",
      "Epoch 869: acc=0.8625, nmi=0.9192\n",
      "stage3\n",
      "Epoch 870: acc=0.8725, nmi=0.9286\n",
      "stage3\n",
      "Epoch 871: acc=0.8600, nmi=0.9235\n",
      "stage3\n",
      "Epoch 872: acc=0.8475, nmi=0.9205\n",
      "stage3\n",
      "Epoch 873: acc=0.8700, nmi=0.9281\n",
      "stage3\n",
      "Epoch 874: acc=0.8400, nmi=0.9128\n",
      "stage3\n",
      "Epoch 875: acc=0.8350, nmi=0.9096\n",
      "stage3\n",
      "Epoch 876: acc=0.8475, nmi=0.9199\n",
      "stage3\n",
      "Epoch 877: acc=0.8400, nmi=0.9157\n",
      "stage3\n",
      "Epoch 878: acc=0.8650, nmi=0.9214\n",
      "stage3\n",
      "Epoch 879: acc=0.8650, nmi=0.9204\n",
      "stage3\n",
      "Epoch 880: acc=0.8550, nmi=0.9205\n",
      "stage3\n",
      "Epoch 881: acc=0.8600, nmi=0.9260\n",
      "stage3\n",
      "Epoch 882: acc=0.8725, nmi=0.9247\n",
      "stage3\n",
      "Epoch 883: acc=0.8525, nmi=0.9193\n",
      "stage3\n",
      "Epoch 884: acc=0.8675, nmi=0.9232\n",
      "stage3\n",
      "Epoch 885: acc=0.8625, nmi=0.9240\n",
      "stage3\n",
      "Epoch 886: acc=0.8725, nmi=0.9249\n",
      "stage3\n",
      "Epoch 887: acc=0.8725, nmi=0.9261\n",
      "stage3\n",
      "Epoch 888: acc=0.8700, nmi=0.9253\n",
      "stage3\n",
      "Epoch 889: acc=0.8625, nmi=0.9240\n",
      "stage3\n",
      "Epoch 890: acc=0.8475, nmi=0.9186\n",
      "stage3\n",
      "Epoch 891: acc=0.8675, nmi=0.9231\n",
      "stage3\n",
      "Epoch 892: acc=0.8725, nmi=0.9266\n",
      "stage3\n",
      "Epoch 893: acc=0.8575, nmi=0.9188\n",
      "stage3\n",
      "Epoch 894: acc=0.8700, nmi=0.9239\n",
      "stage3\n",
      "Epoch 895: acc=0.8650, nmi=0.9217\n",
      "stage3\n",
      "Epoch 896: acc=0.8500, nmi=0.9203\n",
      "stage3\n",
      "Epoch 897: acc=0.8475, nmi=0.9174\n",
      "stage3\n",
      "Epoch 898: acc=0.8500, nmi=0.9180\n",
      "stage3\n",
      "Epoch 899: acc=0.8475, nmi=0.9188\n",
      "stage3\n",
      "Epoch 900: acc=0.8600, nmi=0.9182\n",
      "stage3\n",
      "Epoch 901: acc=0.8550, nmi=0.9264\n",
      "stage3\n",
      "Epoch 902: acc=0.8425, nmi=0.9152\n",
      "stage3\n",
      "Epoch 903: acc=0.8575, nmi=0.9229\n",
      "stage3\n",
      "Epoch 904: acc=0.8450, nmi=0.9174\n",
      "stage3\n",
      "Epoch 905: acc=0.8425, nmi=0.9144\n",
      "stage3\n",
      "Epoch 906: acc=0.8675, nmi=0.9227\n",
      "stage3\n",
      "Epoch 907: acc=0.8450, nmi=0.9174\n",
      "stage3\n",
      "Epoch 908: acc=0.8450, nmi=0.9168\n",
      "stage3\n",
      "Epoch 909: acc=0.8450, nmi=0.9173\n",
      "stage3\n",
      "Epoch 910: acc=0.8375, nmi=0.9100\n",
      "stage3\n",
      "Epoch 911: acc=0.8400, nmi=0.9133\n",
      "stage3\n",
      "Epoch 912: acc=0.8525, nmi=0.9208\n",
      "stage3\n",
      "Epoch 913: acc=0.8550, nmi=0.9216\n",
      "stage3\n",
      "Epoch 914: acc=0.8425, nmi=0.9105\n",
      "stage3\n",
      "Epoch 915: acc=0.8525, nmi=0.9211\n",
      "stage3\n",
      "Epoch 916: acc=0.8575, nmi=0.9232\n",
      "stage3\n",
      "Epoch 917: acc=0.8150, nmi=0.9090\n",
      "stage3\n",
      "Epoch 918: acc=0.8325, nmi=0.9117\n",
      "stage3\n",
      "Epoch 919: acc=0.8250, nmi=0.9089\n",
      "stage3\n",
      "Epoch 920: acc=0.8350, nmi=0.9109\n",
      "stage3\n",
      "Epoch 921: acc=0.8225, nmi=0.9072\n",
      "stage3\n",
      "Epoch 922: acc=0.8225, nmi=0.9155\n",
      "stage3\n",
      "Epoch 923: acc=0.8300, nmi=0.9137\n",
      "stage3\n",
      "Epoch 924: acc=0.8275, nmi=0.9114\n",
      "stage3\n",
      "Epoch 925: acc=0.8350, nmi=0.9139\n",
      "stage3\n",
      "Epoch 926: acc=0.8300, nmi=0.9105\n",
      "stage3\n",
      "Epoch 927: acc=0.8350, nmi=0.9109\n",
      "stage3\n",
      "Epoch 928: acc=0.8175, nmi=0.9108\n",
      "stage3\n",
      "Epoch 929: acc=0.8300, nmi=0.9106\n",
      "stage3\n",
      "Epoch 930: acc=0.8000, nmi=0.9063\n",
      "stage3\n",
      "Epoch 931: acc=0.8250, nmi=0.9045\n",
      "stage3\n",
      "Epoch 932: acc=0.8125, nmi=0.9066\n",
      "stage3\n",
      "Epoch 933: acc=0.8375, nmi=0.9112\n",
      "stage3\n",
      "Epoch 934: acc=0.8100, nmi=0.9040\n",
      "stage3\n",
      "Epoch 935: acc=0.8325, nmi=0.9119\n",
      "stage3\n",
      "Epoch 936: acc=0.8325, nmi=0.9106\n",
      "stage3\n",
      "Epoch 937: acc=0.8225, nmi=0.9039\n",
      "stage3\n",
      "Epoch 938: acc=0.8250, nmi=0.9156\n",
      "stage3\n",
      "Epoch 939: acc=0.8400, nmi=0.9140\n",
      "best_performence = 0.8950\n"
     ]
    }
   ],
   "source": [
    "# load the pretrained weights \n",
    "ae_state_dict = torch.load('pretrained_weights_original/%s.pkl' % 'orl')\n",
    "rsdsc.ae.load_state_dict(ae_state_dict) \n",
    "print(\"Pretrained ae weights are loaded successfully.\")\n",
    "\n",
    "train(rsdsc, x, y, lr, device=device, alpha=alpha, dim_subspace=dim_subspace, ro=ro, show=show_freq,\\\n",
    "      t0=t0, t_dp=t_dp, k_dp=k_dp, gamma1=gamma1, gamma2=gamma2, gamma3=gamma3, gamma4=gamma4,\\\n",
    "      ratio=ratio, update=update, p=p, rw_time=rw_time, shrink=shrink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:studsc] *",
   "language": "python",
   "name": "conda-env-studsc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
